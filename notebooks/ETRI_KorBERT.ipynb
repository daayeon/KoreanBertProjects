{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import unicodedata\n",
    "import six\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_case_matches_checkpoint(do_lower_case, init_checkpoint):\n",
    "    if not init_checkpoint:\n",
    "        return\n",
    "\n",
    "    m = re.match(\"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt\", init_checkpoint)\n",
    "    if m is None:\n",
    "        return\n",
    "\n",
    "    model_name = m.group(1)\n",
    "\n",
    "    lower_models = [\n",
    "          \"uncased_L-24_H-1024_A-16\", \"uncased_L-12_H-768_A-12\",\n",
    "          \"multilingual_L-12_H-768_A-12\", \"chinese_L-12_H-768_A-12\"\n",
    "    ]\n",
    "\n",
    "    cased_models = [\n",
    "          \"cased_L-12_H-768_A-12\", \"cased_L-24_H-1024_A-16\",\n",
    "          \"multi_cased_L-12_H-768_A-12\"\n",
    "    ]\n",
    "\n",
    "    is_bad_config = False\n",
    "    if model_name in lower_models and not do_lower_case:\n",
    "        is_bad_config = True\n",
    "        actual_flag = \"False\"\n",
    "        case_name = \"lowercased\"\n",
    "        opposite_flag = \"True\"\n",
    "\n",
    "    if model_name in cased_models and do_lower_case:\n",
    "        is_bad_config = True\n",
    "        actual_flag = \"True\"\n",
    "        case_name = \"cased\"\n",
    "        opposite_flag = \"False\"\n",
    "\n",
    "    if is_bad_config:\n",
    "        raise ValueError(\n",
    "            \"You passed in `--do_lower_case=%s` with `--init_checkpoint=%s`. \"\n",
    "            \"However, `%s` seems to be a %s model, so you \"\n",
    "            \"should pass in `--do_lower_case=%s` so that the fine-tuning matches \"\n",
    "            \"how the model was pre-training. If this error is wrong, please \"\n",
    "            \"just comment out this check.\" % (actual_flag, init_checkpoint,\n",
    "                                              model_name, case_name, opposite_flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unicode(text):\n",
    "    if six.PY3:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, bytes):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    elif six.PY2:\n",
    "        if isinstance(text, str):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        elif isinstance(text, unicode):\n",
    "            return text\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    else:\n",
    "        raise ValueError(\"Not running on Python2 or Python 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printable_text(text):\n",
    "    if six.PY3:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, bytes):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    elif six.PY2:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, unicode):\n",
    "            return text.encode(\"utf-8\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    else:\n",
    "        raise ValueError(\"Not running on Python2 or Python 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(vocab_file):\n",
    "    vocab = collections.OrderedDict()\n",
    "    index = 0\n",
    "    with tf.gfile.GFile(vocab_file, \"r\") as reader:\n",
    "        while True:\n",
    "            token = convert_to_unicode(reader.readline())\n",
    "            if not token:\n",
    "                break\n",
    "\n",
    "            ### joonho.lim @ 2019-03-15\n",
    "            if token.find('n_iters=') == 0 or token.find('max_length=') == 0 :\n",
    "                continue\n",
    "            token = token.split('\\t')[0]\n",
    "\n",
    "            token = token.strip()\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_by_vocab(vocab, items):\n",
    "    output = []\n",
    "    for item in items:\n",
    "        output.append(vocab[item])\n",
    "    return output\n",
    "\n",
    "\n",
    "def convert_tokens_to_ids(vocab, tokens):\n",
    "    return convert_by_vocab(vocab, tokens)\n",
    "\n",
    "\n",
    "def convert_ids_to_tokens(inv_vocab, ids):\n",
    "    return convert_by_vocab(inv_vocab, ids)\n",
    "\n",
    "\n",
    "def whitespace_tokenize(text):\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullTokenizer(object):\n",
    "\n",
    "    def __init__(self, vocab_file, do_lower_case=True):\n",
    "        self.vocab = load_vocab(vocab_file)\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n",
    "        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        split_tokens = []\n",
    "        for token in self.basic_tokenizer.tokenize(text):\n",
    "            ### joonho.lim @ 2019-03-15\n",
    "            token += '_'\n",
    "            for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
    "                split_tokens.append(sub_token)\n",
    "\n",
    "        return split_tokens\n",
    "\n",
    "    def convert_tokens_to_ids(self, tokens):\n",
    "        return convert_by_vocab(self.vocab, tokens)\n",
    "\n",
    "    def convert_ids_to_tokens(self, ids):\n",
    "        return convert_by_vocab(self.inv_vocab, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTokenizer(object):\n",
    "\n",
    "    def __init__(self, do_lower_case=True):\n",
    "        self.do_lower_case = do_lower_case\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        text = convert_to_unicode(text)\n",
    "        text = self._clean_text(text)\n",
    "\n",
    "        orig_tokens = whitespace_tokenize(text)\n",
    "        split_tokens = []\n",
    "        for token in orig_tokens:\n",
    "            if self.do_lower_case:\n",
    "                token = token.lower()\n",
    "                token = self._run_strip_accents(token)\n",
    "            split_tokens.extend(self._run_split_on_punc(token))\n",
    "\n",
    "        output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n",
    "        return output_tokens\n",
    "\n",
    "    def _run_strip_accents(self, text):\n",
    "        text = unicodedata.normalize(\"NFD\", text)\n",
    "        output = []\n",
    "        for char in text:\n",
    "            cat = unicodedata.category(char)\n",
    "            if cat == \"Mn\":\n",
    "                continue\n",
    "            output.append(char)\n",
    "        return \"\".join(output)\n",
    "\n",
    "    def _run_split_on_punc(self, text):\n",
    "        chars = list(text)\n",
    "        i = 0\n",
    "        start_new_word = True\n",
    "        output = []\n",
    "        while i < len(chars):\n",
    "            char = chars[i]\n",
    "            if _is_punctuation(char):\n",
    "                output.append([char])\n",
    "                start_new_word = True\n",
    "            else:\n",
    "                if start_new_word:\n",
    "                    output.append([])\n",
    "                start_new_word = False\n",
    "                output[-1].append(char)\n",
    "            i += 1\n",
    "        return [\"\".join(x) for x in output]\n",
    "\n",
    "    def _tokenize_chinese_chars(self, text):\n",
    "        output = []\n",
    "        for char in text:\n",
    "            cp = ord(char)\n",
    "            if self._is_chinese_char(cp):\n",
    "                output.append(\" \")\n",
    "                output.append(char)\n",
    "                output.append(\" \")\n",
    "            else:\n",
    "                output.append(char)\n",
    "        return \"\".join(output)\n",
    "\n",
    "    def _is_chinese_char(self, cp):\n",
    "        if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n",
    "            (cp >= 0x3400 and cp <= 0x4DBF) or  #\n",
    "            (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n",
    "            (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n",
    "            (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n",
    "            (cp >= 0x2B820 and cp <= 0x2CEAF) or\n",
    "            (cp >= 0xF900 and cp <= 0xFAFF) or  #\n",
    "            (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        output = []\n",
    "        for char in text:\n",
    "            cp = ord(char)\n",
    "            if cp == 0 or cp == 0xfffd or _is_control(char):\n",
    "                continue\n",
    "            if _is_whitespace(char):\n",
    "                output.append(\" \")\n",
    "            else:\n",
    "                output.append(char)\n",
    "        return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordpieceTokenizer(object):\n",
    "\n",
    "    def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n",
    "        self.vocab = vocab\n",
    "        self.unk_token = unk_token\n",
    "        self.max_input_chars_per_word = max_input_chars_per_word\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        text = convert_to_unicode(text)\n",
    "\n",
    "        output_tokens = []\n",
    "        for token in whitespace_tokenize(text):\n",
    "            chars = list(token)\n",
    "            if len(chars) > self.max_input_chars_per_word:\n",
    "                output_tokens.append(self.unk_token)\n",
    "                continue\n",
    "\n",
    "            is_bad = False\n",
    "            start = 0\n",
    "            sub_tokens = []\n",
    "            while start < len(chars):\n",
    "                end = len(chars)\n",
    "                cur_substr = None\n",
    "                while start < end:\n",
    "                    substr = \"\".join(chars[start:end])\n",
    "                    ### joonho.lim @ 2019-03-15\n",
    "                    # if start > 0:\n",
    "                    # substr = \"##\" + substr\n",
    "                    if substr in self.vocab:\n",
    "                        cur_substr = substr\n",
    "                        break\n",
    "                    end -= 1\n",
    "                if cur_substr is None:\n",
    "                    is_bad = True\n",
    "                    break\n",
    "                sub_tokens.append(cur_substr)\n",
    "                start = end\n",
    "            if is_bad:\n",
    "                output_tokens.append(self.unk_token)\n",
    "            else:\n",
    "                output_tokens.extend(sub_tokens)\n",
    "        return output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_whitespace(char):\n",
    "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat == \"Zs\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _is_control(char):\n",
    "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return False\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"C\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def _is_punctuation(char):\n",
    "    return char == ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `run_classifier.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Jupyter notebook에서 사용시에만 필요\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "## Required parameters\n",
    "flags.DEFINE_string(\n",
    "    \"data_dir\", None,\n",
    "    \"The input data dir. Should contain the .tsv files (or other data files) \"\n",
    "    \"for the task.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"bert_config_file\", None,\n",
    "    \"The config json file corresponding to the pre-trained BERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"task_name\", None, \"The name of the task to train.\")\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\", None,\n",
    "                    \"The vocabulary file that the BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_dir\", None,\n",
    "    \"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "## Other parameters\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"init_checkpoint\", None,\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", True,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_seq_length\", 128,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_train\", False, \"Whether to run training.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_eval\", False, \"Whether to run eval on the dev set.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_predict\", False,\n",
    "    \"Whether to run the model in inference mode on the test set.\")\n",
    "\n",
    "flags.DEFINE_integer(\"train_batch_size\", 32, \"Total batch size for training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"eval_batch_size\", 8, \"Total batch size for eval.\")\n",
    "\n",
    "flags.DEFINE_integer(\"predict_batch_size\", 8, \"Total batch size for predict.\")\n",
    "\n",
    "flags.DEFINE_float(\"learning_rate\", 5e-5, \"The initial learning rate for Adam.\")\n",
    "\n",
    "flags.DEFINE_float(\"num_train_epochs\", 3.0,\n",
    "                   \"Total number of training epochs to perform.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"warmup_proportion\", 0.1,\n",
    "    \"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    \"E.g., 0.1 = 10% of training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"save_checkpoints_steps\", 1000,\n",
    "                     \"How often to save the model checkpoint.\")\n",
    "\n",
    "flags.DEFINE_integer(\"iterations_per_loop\", 1000,\n",
    "                     \"How many steps to make in each estimator call.\")\n",
    "\n",
    "flags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU/CPU.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"tpu_name\", None,\n",
    "    \"The Cloud TPU to use for training. This should be either the name \"\n",
    "    \"used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 \"\n",
    "    \"url.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"tpu_zone\", None,\n",
    "    \"[Optional] GCE zone where the Cloud TPU is located in. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\n",
    "    \"gcp_project\", None,\n",
    "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "tf.flags.DEFINE_string(\"master\", None, \"[Optional] TensorFlow master URL.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"num_tpu_cores\", 8,\n",
    "    \"Only used if `use_tpu` is True. Total number of TPU cores to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.warmup_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample:\n",
    "    \n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "    When running eval/predict on the TPU, we need to pad the number of examples\n",
    "    to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "    size. The alternative is to drop the last batch, which is bad because it means\n",
    "    the entire output data won't be generated.\n",
    "    We use this class instead of `None` because treating `None` as padding\n",
    "    battches could cause silent errors.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "               input_ids,\n",
    "               input_mask,\n",
    "               segment_ids,\n",
    "               label_id,\n",
    "               is_real_example=True):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.is_real_example = is_real_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    \n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with tf.gfile.Open(input_file, \"r\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "            return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MrpcProcessor(DataProcessor):\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = tokenization.convert_to_unicode(line[3])\n",
    "            text_b = tokenization.convert_to_unicode(line[4])\n",
    "            if set_type == \"test\":\n",
    "                label = \"0\"\n",
    "            else:\n",
    "                label = tokenization.convert_to_unicode(line[0])\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_single_example(ex_index, example, label_list, max_seq_length,\n",
    "                           tokenizer):\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        return InputFeatures(\n",
    "            input_ids=[0] * max_seq_length,\n",
    "            input_mask=[0] * max_seq_length,\n",
    "            segment_ids=[0] * max_seq_length,\n",
    "            label_id=0,\n",
    "            is_real_example=False)\n",
    "\n",
    "    label_map = {}\n",
    "    for (i, label) in enumerate(label_list):\n",
    "        label_map[label] = i\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    tokens_b = None\n",
    "    if example.text_b:\n",
    "        tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "    if tokens_b:\n",
    "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "    else:\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "        \n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    if tokens_b:\n",
    "        for token in tokens_b:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(1)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(1)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    label_id = label_map[example.label]\n",
    "    if ex_index < 5:\n",
    "        tf.logging.info(\"*** Example ***\")\n",
    "        tf.logging.info(\"guid: %s\" % (example.guid))\n",
    "        tf.logging.info(\"tokens: %s\" % \" \".join(\n",
    "            [printable_text(x) for x in tokens]))\n",
    "        tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "        tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "        tf.logging.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "        tf.logging.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "    feature = InputFeatures(\n",
    "          input_ids=input_ids,\n",
    "          input_mask=input_mask,\n",
    "          segment_ids=segment_ids,\n",
    "          label_id=label_id,\n",
    "          is_real_example=True)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_based_convert_examples_to_features(\n",
    "    examples, label_list, max_seq_length, tokenizer, output_file):\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        feature = convert_single_example(ex_index, example, label_list,\n",
    "                                         max_seq_length, tokenizer)\n",
    "\n",
    "        def create_int_feature(values):\n",
    "            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
    "            return f\n",
    "\n",
    "        features = collections.OrderedDict()\n",
    "        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
    "        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
    "        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
    "        features[\"label_ids\"] = create_int_feature([feature.label_id])\n",
    "        features[\"is_real_example\"] = create_int_feature(\n",
    "            [int(feature.is_real_example)])\n",
    "\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
    "                                drop_remainder):\n",
    "    name_to_features = {\n",
    "          \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "          \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "          \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "          \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "          \"is_real_example\": tf.FixedLenFeature([], tf.int64),}\n",
    "\n",
    "    def _decode_record(record, name_to_features):\n",
    "        example = tf.parse_single_example(record, name_to_features)\n",
    "\n",
    "        for name in list(example.keys()):\n",
    "            t = example[name]\n",
    "            if t.dtype == tf.int64:\n",
    "                t = tf.to_int32(t)\n",
    "            example[name] = t\n",
    "\n",
    "        return example\n",
    "    \n",
    "    def input_fn(params):\n",
    "        batch_size = params[\"batch_size\"]\n",
    "\n",
    "        d = tf.data.TFRecordDataset(input_file)\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "\n",
    "            d = d.apply(\n",
    "                tf.contrib.data.map_and_batch(\n",
    "                    lambda record: _decode_record(record, name_to_features),\n",
    "                    batch_size=batch_size,\n",
    "                    drop_remainder=drop_remainder))\n",
    "\n",
    "        return d\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `modeling.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                   vocab_size,\n",
    "                   hidden_size=768,\n",
    "                   num_hidden_layers=12,\n",
    "                   num_attention_heads=12,\n",
    "                   intermediate_size=3072,\n",
    "                   hidden_act=\"gelu\",\n",
    "                   hidden_dropout_prob=0.1,\n",
    "                   attention_probs_dropout_prob=0.1,\n",
    "                   max_position_embeddings=512,\n",
    "                   type_vocab_size=16,\n",
    "                   initializer_range=0.02):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, json_object):\n",
    "        config = BertConfig(vocab_size=None)\n",
    "        for (key, value) in six.iteritems(json_object):\n",
    "            config.__dict__[key] = value\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_json_file(cls, json_file):\n",
    "        with tf.gfile.GFile(json_file, \"r\") as reader:\n",
    "            text = reader.read()\n",
    "        return cls.from_dict(json.loads(text))\n",
    "\n",
    "    def to_dict(self):\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "\n",
    "    def to_json_string(self):\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 is_training,\n",
    "                 input_ids,\n",
    "                 input_mask=None,\n",
    "                 token_type_ids=None,\n",
    "                 use_one_hot_embeddings=False,\n",
    "                 scope=None):\n",
    "        config = copy.deepcopy(config)\n",
    "        if not is_training:\n",
    "            config.hidden_dropout_prob = 0.0\n",
    "            config.attention_probs_dropout_prob = 0.0\n",
    "\n",
    "        input_shape = get_shape_list(input_ids, expected_rank=2)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_length = input_shape[1]\n",
    "\n",
    "        if input_mask is None:\n",
    "            input_mask = tf.ones(shape=[batch_size, seq_length], dtype=tf.int32)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = tf.zeros(shape=[batch_size, seq_length], dtype=tf.int32)\n",
    "\n",
    "        with tf.variable_scope(scope, default_name=\"bert\"):\n",
    "            with tf.variable_scope(\"embeddings\"):\n",
    "                (self.embedding_output, self.embedding_table) = embedding_lookup(\n",
    "                    input_ids=input_ids,\n",
    "                    vocab_size=config.vocab_size,\n",
    "                    embedding_size=config.hidden_size,\n",
    "                    initializer_range=config.initializer_range,\n",
    "                    word_embedding_name=\"word_embeddings\",\n",
    "                    use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "                \n",
    "                self.embedding_output = embedding_postprocessor(\n",
    "                    input_tensor=self.embedding_output,\n",
    "                    use_token_type=True,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    token_type_vocab_size=config.type_vocab_size,\n",
    "                    token_type_embedding_name=\"token_type_embeddings\",\n",
    "                    use_position_embeddings=True,\n",
    "                    position_embedding_name=\"position_embeddings\",\n",
    "                    initializer_range=config.initializer_range,\n",
    "                    max_position_embeddings=config.max_position_embeddings,\n",
    "                    dropout_prob=config.hidden_dropout_prob)\n",
    "\n",
    "            with tf.variable_scope(\"encoder\"):\n",
    "                attention_mask = create_attention_mask_from_input_mask(\n",
    "                    input_ids, input_mask)\n",
    "\n",
    "                self.all_encoder_layers = transformer_model(\n",
    "                    input_tensor=self.embedding_output,\n",
    "                    attention_mask=attention_mask,\n",
    "                    hidden_size=config.hidden_size,\n",
    "                    num_hidden_layers=config.num_hidden_layers,\n",
    "                    num_attention_heads=config.num_attention_heads,\n",
    "                    intermediate_size=config.intermediate_size,\n",
    "                    intermediate_act_fn=get_activation(config.hidden_act),\n",
    "                    hidden_dropout_prob=config.hidden_dropout_prob,\n",
    "                    attention_probs_dropout_prob=config.attention_probs_dropout_prob,\n",
    "                    initializer_range=config.initializer_range,\n",
    "                    do_return_all_layers=True)\n",
    "\n",
    "            self.sequence_output = self.all_encoder_layers[-1]\n",
    "            with tf.variable_scope(\"pooler\"):\n",
    "                first_token_tensor = tf.squeeze(self.sequence_output[:, 0:1, :], axis=1)\n",
    "                self.pooled_output = tf.layers.dense(\n",
    "                    first_token_tensor,\n",
    "                    config.hidden_size,\n",
    "                    activation=tf.tanh,\n",
    "                    kernel_initializer=create_initializer(config.initializer_range))\n",
    "\n",
    "    def get_pooled_output(self):\n",
    "        return self.pooled_output\n",
    "\n",
    "    def get_sequence_output(self):\n",
    "        return self.sequence_output\n",
    "\n",
    "    def get_all_encoder_layers(self):\n",
    "        return self.all_encoder_layers\n",
    "\n",
    "    def get_embedding_output(self):\n",
    "        return self.embedding_output\n",
    "\n",
    "    def get_embedding_table(self):\n",
    "        return self.embedding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    cdf = 0.5 * (1.0 + tf.tanh(\n",
    "          (np.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3)))))\n",
    "    return x * cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(activation_string):\n",
    "    if not isinstance(activation_string, six.string_types):\n",
    "        return activation_string\n",
    "\n",
    "    if not activation_string:\n",
    "        return None\n",
    "\n",
    "    act = activation_string.lower()\n",
    "    if act == \"linear\":\n",
    "        return None\n",
    "    elif act == \"relu\":\n",
    "        return tf.nn.relu\n",
    "    elif act == \"gelu\":\n",
    "        return gelu\n",
    "    elif act == \"tanh\":\n",
    "        return tf.tanh\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported activation: %s\" % act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignment_map_from_checkpoint(tvars, init_checkpoint):\n",
    "    assignment_map = {}\n",
    "    initialized_variable_names = {}\n",
    "\n",
    "    name_to_variable = collections.OrderedDict()\n",
    "    for var in tvars:\n",
    "        name = var.name\n",
    "        m = re.match(\"^(.*):\\\\d+$\", name)\n",
    "        if m is not None:\n",
    "            name = m.group(1)\n",
    "        name_to_variable[name] = var\n",
    "\n",
    "    init_vars = tf.train.list_variables(init_checkpoint)\n",
    "\n",
    "    assignment_map = collections.OrderedDict()\n",
    "    for x in init_vars:\n",
    "        (name, var) = (x[0], x[1])\n",
    "        if name not in name_to_variable:\n",
    "            continue\n",
    "        assignment_map[name] = name\n",
    "        initialized_variable_names[name] = 1\n",
    "        initialized_variable_names[name + \":0\"] = 1\n",
    "\n",
    "    return (assignment_map, initialized_variable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(input_tensor, dropout_prob):\n",
    "    if dropout_prob is None or dropout_prob == 0.0:\n",
    "        return input_tensor\n",
    "\n",
    "    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(input_tensor, name=None):\n",
    "    return tf.contrib.layers.layer_norm(\n",
    "        inputs=input_tensor, begin_norm_axis=-1, begin_params_axis=-1, scope=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm_and_dropout(input_tensor, dropout_prob, name=None):\n",
    "    output_tensor = layer_norm(input_tensor, name)\n",
    "    output_tensor = dropout(output_tensor, dropout_prob)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initializer(initializer_range=0.02):\n",
    "    return tf.truncated_normal_initializer(stddev=initializer_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_lookup(input_ids,\n",
    "                     vocab_size,\n",
    "                     embedding_size=128,\n",
    "                     initializer_range=0.02,\n",
    "                     word_embedding_name=\"word_embeddings\",\n",
    "                     use_one_hot_embeddings=False):\n",
    "    if input_ids.shape.ndims == 2:\n",
    "        input_ids = tf.expand_dims(input_ids, axis=[-1])\n",
    "\n",
    "    embedding_table = tf.get_variable(\n",
    "          name=word_embedding_name,\n",
    "          shape=[vocab_size, embedding_size],\n",
    "          initializer=create_initializer(initializer_range))\n",
    "\n",
    "    flat_input_ids = tf.reshape(input_ids, [-1])\n",
    "    if use_one_hot_embeddings:\n",
    "        one_hot_input_ids = tf.one_hot(flat_input_ids, depth=vocab_size)\n",
    "        output = tf.matmul(one_hot_input_ids, embedding_table)\n",
    "    else:\n",
    "        output = tf.gather(embedding_table, flat_input_ids)\n",
    "\n",
    "    input_shape = get_shape_list(input_ids)\n",
    "\n",
    "    output = tf.reshape(output,\n",
    "                        input_shape[0:-1] + [input_shape[-1] * embedding_size])\n",
    "    return (output, embedding_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_postprocessor(input_tensor,\n",
    "                            use_token_type=False,\n",
    "                            token_type_ids=None,\n",
    "                            token_type_vocab_size=16,\n",
    "                            token_type_embedding_name=\"token_type_embeddings\",\n",
    "                            use_position_embeddings=True,\n",
    "                            position_embedding_name=\"position_embeddings\",\n",
    "                            initializer_range=0.02,\n",
    "                            max_position_embeddings=512,\n",
    "                            dropout_prob=0.1):\n",
    "    input_shape = get_shape_list(input_tensor, expected_rank=3)\n",
    "    batch_size = input_shape[0]\n",
    "    seq_length = input_shape[1]\n",
    "    width = input_shape[2]\n",
    "\n",
    "    output = input_tensor\n",
    "\n",
    "    if use_token_type:\n",
    "        if token_type_ids is None:\n",
    "            raise ValueError(\"`token_type_ids` must be specified if\"\n",
    "                             \"`use_token_type` is True.\")\n",
    "        token_type_table = tf.get_variable(\n",
    "            name=token_type_embedding_name,\n",
    "            shape=[token_type_vocab_size, width],\n",
    "            initializer=create_initializer(initializer_range))\n",
    "        flat_token_type_ids = tf.reshape(token_type_ids, [-1])\n",
    "        one_hot_ids = tf.one_hot(flat_token_type_ids, depth=token_type_vocab_size)\n",
    "        token_type_embeddings = tf.matmul(one_hot_ids, token_type_table)\n",
    "        token_type_embeddings = tf.reshape(token_type_embeddings,\n",
    "                                           [batch_size, seq_length, width])\n",
    "        output += token_type_embeddings\n",
    "\n",
    "    if use_position_embeddings:\n",
    "        assert_op = tf.assert_less_equal(seq_length, max_position_embeddings)\n",
    "        with tf.control_dependencies([assert_op]):\n",
    "            full_position_embeddings = tf.get_variable(\n",
    "                  name=position_embedding_name,\n",
    "                  shape=[max_position_embeddings, width],\n",
    "                  initializer=create_initializer(initializer_range))\n",
    "            position_embeddings = tf.slice(full_position_embeddings, [0, 0],\n",
    "                                           [seq_length, -1])\n",
    "            num_dims = len(output.shape.as_list())\n",
    "\n",
    "            position_broadcast_shape = []\n",
    "            for _ in range(num_dims - 2):\n",
    "                position_broadcast_shape.append(1)\n",
    "            position_broadcast_shape.extend([seq_length, width])\n",
    "            position_embeddings = tf.reshape(position_embeddings,\n",
    "                                             position_broadcast_shape)\n",
    "            output += position_embeddings\n",
    "\n",
    "    output = layer_norm_and_dropout(output, dropout_prob)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask_from_input_mask(from_tensor, to_mask):\n",
    "    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n",
    "    batch_size = from_shape[0]\n",
    "    from_seq_length = from_shape[1]\n",
    "\n",
    "    to_shape = get_shape_list(to_mask, expected_rank=2)\n",
    "    to_seq_length = to_shape[1]\n",
    "\n",
    "    to_mask = tf.cast(\n",
    "          tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n",
    "\n",
    "    broadcast_ones = tf.ones(\n",
    "          shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n",
    "    \n",
    "    mask = broadcast_ones * to_mask\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_layer(from_tensor,\n",
    "                    to_tensor,\n",
    "                    attention_mask=None,\n",
    "                    num_attention_heads=1,\n",
    "                    size_per_head=512,\n",
    "                    query_act=None,\n",
    "                    key_act=None,\n",
    "                    value_act=None,\n",
    "                    attention_probs_dropout_prob=0.0,\n",
    "                    initializer_range=0.02,\n",
    "                    do_return_2d_tensor=False,\n",
    "                    batch_size=None,\n",
    "                    from_seq_length=None,\n",
    "                    to_seq_length=None):\n",
    "\n",
    "    def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n",
    "                             seq_length, width):\n",
    "        output_tensor = tf.reshape(\n",
    "            input_tensor, [batch_size, seq_length, num_attention_heads, width])\n",
    "\n",
    "        output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n",
    "        return output_tensor\n",
    "\n",
    "    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n",
    "    to_shape = get_shape_list(to_tensor, expected_rank=[2, 3])\n",
    "\n",
    "    if len(from_shape) != len(to_shape):\n",
    "        raise ValueError(\n",
    "            \"The rank of `from_tensor` must match the rank of `to_tensor`.\")\n",
    "\n",
    "    if len(from_shape) == 3:\n",
    "        batch_size = from_shape[0]\n",
    "        from_seq_length = from_shape[1]\n",
    "        to_seq_length = to_shape[1]\n",
    "    elif len(from_shape) == 2:\n",
    "        if (batch_size is None or from_seq_length is None or to_seq_length is None):\n",
    "            raise ValueError(\n",
    "              \"When passing in rank 2 tensors to attention_layer, the values \"\n",
    "              \"for `batch_size`, `from_seq_length`, and `to_seq_length` \"\n",
    "              \"must all be specified.\")\n",
    "\n",
    "    from_tensor_2d = reshape_to_matrix(from_tensor)\n",
    "    to_tensor_2d = reshape_to_matrix(to_tensor)\n",
    "\n",
    "    query_layer = tf.layers.dense(\n",
    "        from_tensor_2d,\n",
    "        num_attention_heads * size_per_head,\n",
    "        activation=query_act,\n",
    "        name=\"query\",\n",
    "        kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "    key_layer = tf.layers.dense(\n",
    "        to_tensor_2d,\n",
    "        num_attention_heads * size_per_head,\n",
    "        activation=key_act,\n",
    "        name=\"key\",\n",
    "        kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "    value_layer = tf.layers.dense(\n",
    "        to_tensor_2d,\n",
    "        num_attention_heads * size_per_head,\n",
    "        activation=value_act,\n",
    "        name=\"value\",\n",
    "        kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "\n",
    "    query_layer = transpose_for_scores(query_layer, batch_size,\n",
    "                                       num_attention_heads, from_seq_length,\n",
    "                                       size_per_head)\n",
    "\n",
    "    key_layer = transpose_for_scores(key_layer, batch_size, num_attention_heads,\n",
    "                                     to_seq_length, size_per_head)\n",
    "    \n",
    "    attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\n",
    "    attention_scores = tf.multiply(attention_scores,\n",
    "                                   1.0 / math.sqrt(float(size_per_head)))\n",
    "\n",
    "    if attention_mask is not None:\n",
    "        attention_mask = tf.expand_dims(attention_mask, axis=[1])\n",
    "        adder = (1.0 - tf.cast(attention_mask, tf.float32)) * -10000.0\n",
    "        attention_scores += adder\n",
    "\n",
    "    attention_probs = tf.nn.softmax(attention_scores)\n",
    "    attention_probs = dropout(attention_probs, attention_probs_dropout_prob)\n",
    "\n",
    "    value_layer = tf.reshape(\n",
    "        value_layer,\n",
    "        [batch_size, to_seq_length, num_attention_heads, size_per_head])\n",
    "    value_layer = tf.transpose(value_layer, [0, 2, 1, 3])\n",
    "    context_layer = tf.matmul(attention_probs, value_layer)\n",
    "    context_layer = tf.transpose(context_layer, [0, 2, 1, 3])\n",
    "\n",
    "    if do_return_2d_tensor:\n",
    "        context_layer = tf.reshape(\n",
    "            context_layer,\n",
    "            [batch_size * from_seq_length, num_attention_heads * size_per_head])\n",
    "    else:\n",
    "        context_layer = tf.reshape(\n",
    "            context_layer,\n",
    "            [batch_size, from_seq_length, num_attention_heads * size_per_head])\n",
    "\n",
    "    return context_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_model(input_tensor,\n",
    "                      attention_mask=None,\n",
    "                      hidden_size=768,\n",
    "                      num_hidden_layers=12,\n",
    "                      num_attention_heads=12,\n",
    "                      intermediate_size=3072,\n",
    "                      intermediate_act_fn=gelu,\n",
    "                      hidden_dropout_prob=0.1,\n",
    "                      attention_probs_dropout_prob=0.1,\n",
    "                      initializer_range=0.02,\n",
    "                      do_return_all_layers=False):\n",
    "    if hidden_size % num_attention_heads != 0:\n",
    "        raise ValueError(\n",
    "            \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "            \"heads (%d)\" % (hidden_size, num_attention_heads))\n",
    "\n",
    "    attention_head_size = int(hidden_size / num_attention_heads)\n",
    "    input_shape = get_shape_list(input_tensor, expected_rank=3)\n",
    "    batch_size = input_shape[0]\n",
    "    seq_length = input_shape[1]\n",
    "    input_width = input_shape[2]\n",
    "\n",
    "    if input_width != hidden_size:\n",
    "        raise ValueError(\"The width of the input tensor (%d) != hidden size (%d)\" %\n",
    "                         (input_width, hidden_size))\n",
    "\n",
    "    prev_output = reshape_to_matrix(input_tensor)\n",
    "\n",
    "    all_layer_outputs = []\n",
    "    for layer_idx in range(num_hidden_layers):\n",
    "        with tf.variable_scope(\"layer_%d\" % layer_idx):\n",
    "            layer_input = prev_output\n",
    "\n",
    "            with tf.variable_scope(\"attention\"):\n",
    "                attention_heads = []\n",
    "                with tf.variable_scope(\"self\"):\n",
    "                    attention_head = attention_layer(\n",
    "                          from_tensor=layer_input,\n",
    "                          to_tensor=layer_input,\n",
    "                          attention_mask=attention_mask,\n",
    "                          num_attention_heads=num_attention_heads,\n",
    "                          size_per_head=attention_head_size,\n",
    "                          attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "                          initializer_range=initializer_range,\n",
    "                          do_return_2d_tensor=True,\n",
    "                          batch_size=batch_size,\n",
    "                          from_seq_length=seq_length,\n",
    "                          to_seq_length=seq_length)\n",
    "                    attention_heads.append(attention_head)\n",
    "\n",
    "                attention_output = None\n",
    "                if len(attention_heads) == 1:\n",
    "                    attention_output = attention_heads[0]\n",
    "                else:\n",
    "                    attention_output = tf.concat(attention_heads, axis=-1)\n",
    "\n",
    "                with tf.variable_scope(\"output\"):\n",
    "                    attention_output = tf.layers.dense(\n",
    "                        attention_output,\n",
    "                        hidden_size,\n",
    "                        kernel_initializer=create_initializer(initializer_range))\n",
    "                    attention_output = dropout(attention_output, hidden_dropout_prob)\n",
    "                    attention_output = layer_norm(attention_output + layer_input)\n",
    "\n",
    "            with tf.variable_scope(\"intermediate\"):\n",
    "                intermediate_output = tf.layers.dense(\n",
    "                    attention_output,\n",
    "                    intermediate_size,\n",
    "                    activation=intermediate_act_fn,\n",
    "                    kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "            with tf.variable_scope(\"output\"):\n",
    "                layer_output = tf.layers.dense(\n",
    "                    intermediate_output,\n",
    "                    hidden_size,\n",
    "                    kernel_initializer=create_initializer(initializer_range))\n",
    "                layer_output = dropout(layer_output, hidden_dropout_prob)\n",
    "                layer_output = layer_norm(layer_output + attention_output)\n",
    "                prev_output = layer_output\n",
    "                all_layer_outputs.append(layer_output)\n",
    "\n",
    "    if do_return_all_layers:\n",
    "        final_outputs = []\n",
    "        for layer_output in all_layer_outputs:\n",
    "            final_output = reshape_from_matrix(layer_output, input_shape)\n",
    "            final_outputs.append(final_output)\n",
    "        return final_outputs\n",
    "    else:\n",
    "        final_output = reshape_from_matrix(prev_output, input_shape)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_list(tensor, expected_rank=None, name=None):\n",
    "    if name is None:\n",
    "        name = tensor.name\n",
    "\n",
    "    if expected_rank is not None:\n",
    "        assert_rank(tensor, expected_rank, name)\n",
    "\n",
    "    shape = tensor.shape.as_list()\n",
    "\n",
    "    non_static_indexes = []\n",
    "    for (index, dim) in enumerate(shape):\n",
    "        if dim is None:\n",
    "            non_static_indexes.append(index)\n",
    "\n",
    "    if not non_static_indexes:\n",
    "        return shape\n",
    "\n",
    "    dyn_shape = tf.shape(tensor)\n",
    "    for index in non_static_indexes:\n",
    "        shape[index] = dyn_shape[index]\n",
    "    return shape\n",
    "\n",
    "def reshape_to_matrix(input_tensor):\n",
    "    ndims = input_tensor.shape.ndims\n",
    "    if ndims < 2:\n",
    "        raise ValueError(\"Input tensor must have at least rank 2. Shape = %s\" %\n",
    "                         (input_tensor.shape))\n",
    "    if ndims == 2:\n",
    "        return input_tensor\n",
    "\n",
    "    width = input_tensor.shape[-1]\n",
    "    output_tensor = tf.reshape(input_tensor, [-1, width])\n",
    "    return output_tensor\n",
    "\n",
    "\n",
    "def reshape_from_matrix(output_tensor, orig_shape_list):\n",
    "    if len(orig_shape_list) == 2:\n",
    "        return output_tensor\n",
    "\n",
    "    output_shape = get_shape_list(output_tensor)\n",
    "\n",
    "    orig_dims = orig_shape_list[0:-1]\n",
    "    width = output_shape[-1]\n",
    "\n",
    "    return tf.reshape(output_tensor, orig_dims + [width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_rank(tensor, expected_rank, name=None):\n",
    "    if name is None:\n",
    "        name = tensor.name\n",
    "\n",
    "    expected_rank_dict = {}\n",
    "    if isinstance(expected_rank, six.integer_types):\n",
    "        expected_rank_dict[expected_rank] = True\n",
    "    else:\n",
    "        for x in expected_rank:\n",
    "            expected_rank_dict[x] = True\n",
    "\n",
    "    actual_rank = tensor.shape.ndims\n",
    "    if actual_rank not in expected_rank_dict:\n",
    "        scope_name = tf.get_variable_scope().name\n",
    "        raise ValueError(\n",
    "            \"For the tensor `%s` in scope `%s`, the actual rank \"\n",
    "            \"`%d` (shape = %s) is not equal to the expected rank `%s`\" %\n",
    "            (name, scope_name, actual_rank, str(tensor.shape), str(expected_rank)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `end`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
    "                 labels, num_labels, use_one_hot_embeddings):\n",
    "    model = BertModel(\n",
    "        config=bert_config,\n",
    "        is_training=is_training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        token_type_ids=segment_ids,\n",
    "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "\n",
    "    output_layer = model.get_pooled_output() # entire segment\n",
    "#     output_layer = model.get_sequence_output() # token-level segment\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        if is_training:\n",
    "            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "\n",
    "    return (loss, per_example_loss, logits, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps, use_tpu,\n",
    "                     use_one_hot_embeddings):\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        tf.logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            tf.logging.info(\"  name = %s, shape = %s\" % \n",
    "                            (name, features[name].shape))\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "        is_real_example = None\n",
    "        if \"is_real_example\" in features:\n",
    "            is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
    "        else:\n",
    "            is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "        (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
    "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
    "            num_labels, use_one_hot_embeddings)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        initialized_variable_names = {}\n",
    "        scaffold_fn = None\n",
    "        if init_checkpoint:\n",
    "            (assignment_map, initialized_variable_names\n",
    "            ) = get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "            if use_tpu:\n",
    "                def tpu_scaffold():\n",
    "                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "                    return tf.train.Scaffold()\n",
    "                scaffold_fn = tpu_scaffold\n",
    "            else:\n",
    "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "        tf.logging.info(\"**** Trainable Variables ****\")\n",
    "        for var in tvars:\n",
    "            init_string = \"\"\n",
    "            if var.name in initialized_variable_names:\n",
    "                init_string = \", *INIT_FROM_CKPT*\"\n",
    "            tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
    "                            init_string)\n",
    "            \n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = create_optimizer(\n",
    "                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  loss=total_loss,\n",
    "                  train_op=train_op,\n",
    "                  scaffold_fn=scaffold_fn)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
    "                predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "                accuracy = tf.metrics.accuracy(\n",
    "                    labels=label_ids, predictions=predictions, weights=is_real_example)\n",
    "                loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"eval_loss\": loss,\n",
    "                }\n",
    "            eval_metrics = (metric_fn,\n",
    "                            [per_example_loss, label_ids, logits, is_real_example])\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                eval_metrics=eval_metrics,\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        else:\n",
    "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions={\"probabilities\": probabilities},\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        return output_spec\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is not used by this file but is still used by the Colab and\n",
    "# people who depend on it.\n",
    "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
    "    all_input_ids = []\n",
    "    all_input_mask = []\n",
    "    all_segment_ids = []\n",
    "    all_label_ids = []\n",
    "\n",
    "    for feature in features:\n",
    "        all_input_ids.append(feature.input_ids)\n",
    "        all_input_mask.append(feature.input_mask)\n",
    "        all_segment_ids.append(feature.segment_ids)\n",
    "        all_label_ids.append(feature.label_id)\n",
    "\n",
    "    def input_fn(params):\n",
    "        batch_size = params[\"batch_size\"]\n",
    "\n",
    "        num_examples = len(features)\n",
    "        d = tf.data.Dataset.from_tensor_slices({\n",
    "            \"input_ids\":\n",
    "                tf.constant(\n",
    "                    all_input_ids, shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"input_mask\":\n",
    "                tf.constant(\n",
    "                    all_input_mask,\n",
    "                    shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"segment_ids\":\n",
    "                tf.constant(\n",
    "                    all_segment_ids,\n",
    "                    shape=[num_examples, seq_length],\n",
    "                    dtype=tf.int32),\n",
    "            \"label_ids\":\n",
    "                tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "        })\n",
    "\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "\n",
    "        d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "        return d\n",
    "\n",
    "    return input_fn\n",
    "\n",
    "\n",
    "# This function is not used by this file but is still used by the Colab and\n",
    "# people who depend on it.\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length,\n",
    "                                 tokenizer):\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "        feature = convert_single_example(ex_index, example, label_list,\n",
    "                                         max_seq_length, tokenizer)\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization.py\n",
    "def create_optimizer(loss, init_lr, num_train_steps, num_warmup_steps, use_tpu):\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)\n",
    "\n",
    "    learning_rate = tf.train.polynomial_decay(\n",
    "        learning_rate,\n",
    "        global_step,\n",
    "        num_train_steps,\n",
    "        end_learning_rate=0.0,\n",
    "        power=1.0,\n",
    "        cycle=False)\n",
    "\n",
    "    if num_warmup_steps:\n",
    "        global_steps_int = tf.cast(global_step, tf.int32)\n",
    "        warmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)\n",
    "\n",
    "        global_steps_float = tf.cast(global_steps_int, tf.float32)\n",
    "        warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)\n",
    "\n",
    "        warmup_percent_done = global_steps_float / warmup_steps_float\n",
    "        warmup_learning_rate = init_lr * warmup_percent_done\n",
    "\n",
    "        is_warmup = tf.cast(global_steps_int < warmup_steps_int, tf.float32)\n",
    "        learning_rate = (\n",
    "            (1.0 - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)\n",
    "\n",
    "    optimizer = AdamWeightDecayOptimizer(\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay_rate=0.01,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-6,\n",
    "        exclude_from_weight_decay=[\"LayerNorm\", \"layer_norm\", \"bias\"])\n",
    "\n",
    "    if use_tpu:\n",
    "        optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
    "\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads = tf.gradients(loss, tvars)\n",
    "\n",
    "    (grads, _) = tf.clip_by_global_norm(grads, clip_norm=1.0)\n",
    "\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        zip(grads, tvars), global_step=global_step)\n",
    "\n",
    "    new_global_step = global_step + 1\n",
    "    train_op = tf.group(train_op, [global_step.assign(new_global_step)])\n",
    "    return train_op\n",
    "\n",
    "\n",
    "class AdamWeightDecayOptimizer(tf.train.Optimizer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 learning_rate,\n",
    "                 weight_decay_rate=0.0,\n",
    "                 beta_1=0.9,\n",
    "                 beta_2=0.999,\n",
    "                 epsilon=1e-6,\n",
    "                 exclude_from_weight_decay=None,\n",
    "                 name=\"AdamWeightDecayOptimizer\"):\n",
    "        super(AdamWeightDecayOptimizer, self).__init__(False, name)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay_rate = weight_decay_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.exclude_from_weight_decay = exclude_from_weight_decay\n",
    "        \n",
    "    def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n",
    "        assignments = []\n",
    "        for (grad, param) in grads_and_vars:\n",
    "            if grad is None or param is None:\n",
    "                continue\n",
    "\n",
    "        param_name = self._get_variable_name(param.name)\n",
    "\n",
    "        m = tf.get_variable(\n",
    "                name=param_name + \"/adam_m\",\n",
    "                shape=param.shape.as_list(),\n",
    "                dtype=tf.float32,\n",
    "                trainable=False,\n",
    "                initializer=tf.zeros_initializer())\n",
    "        v = tf.get_variable(\n",
    "                name=param_name + \"/adam_v\",\n",
    "                shape=param.shape.as_list(),\n",
    "                dtype=tf.float32,\n",
    "                trainable=False,\n",
    "                initializer=tf.zeros_initializer())\n",
    "\n",
    "        next_m = (\n",
    "            tf.multiply(self.beta_1, m) + tf.multiply(1.0 - self.beta_1, grad))\n",
    "        next_v = (\n",
    "            tf.multiply(self.beta_2, v) + tf.multiply(1.0 - self.beta_2,\n",
    "                                                    tf.square(grad)))\n",
    "\n",
    "        update = next_m / (tf.sqrt(next_v) + self.epsilon)\n",
    "\n",
    "        if self._do_use_weight_decay(param_name):\n",
    "            update += self.weight_decay_rate * param\n",
    "\n",
    "        update_with_lr = self.learning_rate * update\n",
    "\n",
    "        next_param = param - update_with_lr\n",
    "\n",
    "        assignments.extend(\n",
    "            [param.assign(next_param),\n",
    "             m.assign(next_m),\n",
    "             v.assign(next_v)])\n",
    "        return tf.group(*assignments, name=name)\n",
    "\n",
    "    def _do_use_weight_decay(self, param_name):\n",
    "        if not self.weight_decay_rate:\n",
    "            return False\n",
    "        if self.exclude_from_weight_decay:\n",
    "            for r in self.exclude_from_weight_decay:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def _get_variable_name(self, param_name):\n",
    "        m = re.match(\"^(.*):\\\\d+$\", param_name)\n",
    "        if m is not None:\n",
    "            param_name = m.group(1)\n",
    "        return param_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.do_train = True\n",
    "FLAGS.do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = {\n",
    "  \"attention_probs_dropout_prob\": 0.1, \n",
    "  \"directionality\": \"bidi\", \n",
    "  \"hidden_act\": \"gelu\", \n",
    "  \"hidden_dropout_prob\": 0.1, \n",
    "  \"hidden_size\": 768, \n",
    "  \"initializer_range\": 0.02, \n",
    "  \"intermediate_size\": 3072, \n",
    "  \"max_position_embeddings\": 512, \n",
    "  \"num_attention_heads\": 12, \n",
    "  \"num_hidden_layers\": 12, \n",
    "  \"pooler_fc_size\": 768, \n",
    "  \"pooler_num_attention_heads\": 12, \n",
    "  \"pooler_num_fc_layers\": 3, \n",
    "  \"pooler_size_per_head\": 128, \n",
    "  \"pooler_type\": \"first_token_transform\", \n",
    "  \"type_vocab_size\": 2, \n",
    "  \"vocab_size\": 30349\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../KorBERT/2_bert_download_002_bert_morp_tensorflow/002_bert_morp_tensorflow/'\n",
    "# FLAGS.bert_config_file = path + 'bert_config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_config = BertConfig.from_json_file(FLAGS.bert_config_file)\n",
    "bert_config = BertConfig.from_dict(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAGS.max_seq_length > bert_config.max_position_embeddings:\n",
    "    raise ValueError(\n",
    "        \"Cannot use sequence length %d because the BERT model \"\n",
    "        \"was only trained up to sequence length %d\" %\n",
    "        (FLAGS.max_seq_length, bert_config.max_position_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.vocab_file = path + 'vocab.korean_morp.list' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = FullTokenizer(\n",
    "    vocab_file=FLAGS.vocab_file,\n",
    "    do_lower_case=FLAGS.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.use_tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use tpu\n",
    "tpu_cluster_resolver = None\n",
    "if FLAGS.use_tpu and FLAGS.tpu_name:\n",
    "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "        FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.iterations_per_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.num_tpu_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=FLAGS.master,\n",
    "    model_dir=FLAGS.output_dir,\n",
    "    save_checkpoints_steps=FLAGS.save_checkpoints_steps, # 1000\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=FLAGS.iterations_per_loop, # 1000\n",
    "        num_shards=FLAGS.num_tpu_cores, # 8\n",
    "        per_host_input_for_training=is_per_host)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow gpu 사용 가능한지 체크\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dacon문자스미싱 processor 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dacon_path = '../dacon문자스미싱/filedown (2)/'\n",
    "df_train = pd.read_csv(dacon_path + 'train.csv')\n",
    "df_test = pd.read_csv(dacon_path + 'public_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eunjeon import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.9 s\n",
      "Wall time: 473 ms\n"
     ]
    }
   ],
   "source": [
    "# pos tagging\n",
    "f = lambda text: ' '.join(['{}/{}'.format(*s) for s in mecab.pos(text)]) \n",
    "%time df_train.text = df_train.text.map(f)\n",
    "%time df_test.text = df_test.text.map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         XXX/SL 은/JX 행성/NNP 산/XSN XXX/SL 팀장/NNG 입니다/VCP...\n",
       "1         오늘/NNG 도/JX 많이/MAG 웃/VV 으시/EP 는/ETM 하루/NNG 시작/...\n",
       "2         안녕/NNG 하/XSV 십니까/EP+EF 고객/NNG 님/XSN ./SY XXX/S...\n",
       "3         XXX/SL 고객/NNG 님/XSN 안녕/NNG 하/XSV 세요/EP+EF XXX/...\n",
       "4         1/SN 월/NNBC 은/JX 새로움/VA+ETN 이/JKS 가득/MAG XXX/S...\n",
       "                                ...                        \n",
       "295940    XXX/SL 고객/NNG 님/XSN !/SF 열심히/MAG 달려왔/VV+EP 던/E...\n",
       "295941    XXX/SL 고객/NNG 님/XSN 실버/NNP 웰빙/NNP 신탁/NNG 이/JKS...\n",
       "295942    한/MM 해/NNG 동안/NNG XXX/SL 은행/NNG 과/JKB 함께/MAG 해...\n",
       "295943    1228/SN (/SSO 금/NNG )/SSC 예금/NNG 및/MAJ 적금/NNG ...\n",
       "295944    안녕/NNG 하/XSV 세요/EP+EF XXX/SL 고객/NNG 님/XSN ./SF...\n",
       "Name: text, Length: 295945, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         XXX/SL 은/JX 행성/NNP 산/XSN XXX/SL 팀장/NNG 입니다/VCP...\n",
       "1         오늘/NNG 도/JX 많이/MAG 웃/VV 으시/EP 는/ETM 하루/NNG 시작/...\n",
       "2         안녕/NNG 하/XSV 십니까/EP+EF 고객/NNG 님/XSN ./SY XXX/S...\n",
       "3         XXX/SL 고객/NNG 님/XSN 안녕/NNG 하/XSV 세요/EP+EF XXX/...\n",
       "4         1/SN 월/NNBC 은/JX 새로움/VA+ETN 이/JKS 가득/MAG XXX/S...\n",
       "                                ...                        \n",
       "295940    XXX/SL 고객/NNG 님/XSN !/SF 열심히/MAG 달려왔/VV+EP 던/E...\n",
       "295941    XXX/SL 고객/NNG 님/XSN 실버/NNP 웰빙/NNP 신탁/NNG 이/JKS...\n",
       "295942    한/MM 해/NNG 동안/NNG XXX/SL 은행/NNG 과/JKB 함께/MAG 해...\n",
       "295943    1228/SN (/SSO 금/NNG )/SSC 예금/NNG 및/MAJ 적금/NNG ...\n",
       "295944    안녕/NNG 하/XSV 세요/EP+EF XXX/SL 고객/NNG 님/XSN ./SF...\n",
       "Name: text, Length: 295945, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((236756, 2), (59189, 2), (236756,), (59189,))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = df_train.set_index('id')\n",
    "df_test = df_test.set_index('id')\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                 df_train[[col for col in df_train.columns if col != 'smishing']], \n",
    "                 df_train['smishing'],\n",
    "                 random_state=42, test_size=.2,\n",
    "                 stratify=df_train['smishing'])\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat((X_train, y_train), axis=1)\n",
    "df_valid = pd.concat((X_valid, y_valid), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(dacon_path + 'train.tsv', sep='\\t')\n",
    "df_valid.to_csv(dacon_path + 'dev.tsv', sep='\\t')\n",
    "df_test.to_csv(dacon_path + 'test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmishingProcessor(DataProcessor):\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = convert_to_unicode(line[2])\n",
    "            if set_type == \"test\":\n",
    "                label = \"0\"\n",
    "            else:\n",
    "                label = convert_to_unicode(line[-1])\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SmishingProcessor()\n",
    "label_list = processor.get_labels()\n",
    "\n",
    "# get train samples\n",
    "train_examples = processor.get_train_examples(dacon_path)\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n",
    "num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.init_checkpoint = path + 'model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_case_matches_checkpoint(FLAGS.do_lower_case,\n",
    "                                 FLAGS.init_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),             # 2\n",
    "    init_checkpoint=FLAGS.init_checkpoint,  # None\n",
    "    learning_rate=FLAGS.learning_rate,      # 5e-05\n",
    "    num_train_steps=num_train_steps,        # 22195\n",
    "    num_warmup_steps=num_warmup_steps,      # 2219\n",
    "    use_tpu=FLAGS.use_tpu,                  # False\n",
    "    use_one_hot_embeddings=FLAGS.use_tpu)   # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x00000207161E2E18>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\jinma\\AppData\\Local\\Temp\\tmpoutmjh21\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\jinma\\\\AppData\\\\Local\\\\Temp\\\\tmpoutmjh21', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000208ADA86908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "# If TPU is not available, this will fall back to normal Estimator on CPU\n",
    "# or GPU\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=FLAGS.use_tpu,                        # False\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=FLAGS.train_batch_size,      # 32\n",
    "    eval_batch_size=FLAGS.eval_batch_size,        # 8\n",
    "    predict_batch_size=FLAGS.predict_batch_size   # 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.output_dir = './output_dir/smishing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.gfile.MakeDirs(FLAGS.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 236756\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-1\n",
      "INFO:tensorflow:tokens: [CLS] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-2\n",
      "INFO:tensorflow:tokens: [CLS] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-3\n",
      "INFO:tensorflow:tokens: [CLS] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-4\n",
      "INFO:tensorflow:tokens: [CLS] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train-5\n",
      "INFO:tensorflow:tokens: [CLS] [SEP]\n",
      "INFO:tensorflow:input_ids: 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:Writing example 10000 of 236756\n",
      "INFO:tensorflow:Writing example 20000 of 236756\n",
      "INFO:tensorflow:Writing example 30000 of 236756\n",
      "INFO:tensorflow:Writing example 40000 of 236756\n",
      "INFO:tensorflow:Writing example 50000 of 236756\n",
      "INFO:tensorflow:Writing example 60000 of 236756\n",
      "INFO:tensorflow:Writing example 70000 of 236756\n",
      "INFO:tensorflow:Writing example 80000 of 236756\n",
      "INFO:tensorflow:Writing example 90000 of 236756\n",
      "INFO:tensorflow:Writing example 100000 of 236756\n",
      "INFO:tensorflow:Writing example 110000 of 236756\n",
      "INFO:tensorflow:Writing example 120000 of 236756\n",
      "INFO:tensorflow:Writing example 130000 of 236756\n",
      "INFO:tensorflow:Writing example 140000 of 236756\n",
      "INFO:tensorflow:Writing example 150000 of 236756\n",
      "INFO:tensorflow:Writing example 160000 of 236756\n",
      "INFO:tensorflow:Writing example 170000 of 236756\n",
      "INFO:tensorflow:Writing example 180000 of 236756\n",
      "INFO:tensorflow:Writing example 190000 of 236756\n",
      "INFO:tensorflow:Writing example 200000 of 236756\n",
      "INFO:tensorflow:Writing example 210000 of 236756\n",
      "INFO:tensorflow:Writing example 220000 of 236756\n",
      "INFO:tensorflow:Writing example 230000 of 236756\n"
     ]
    }
   ],
   "source": [
    "train_file = os.path.join(FLAGS.output_dir, 'train.tf_record')\n",
    "file_based_convert_examples_to_features(\n",
    "    train_examples, label_list, FLAGS.max_seq_length, tokenizer, train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 236756\n",
      "INFO:tensorflow:  Batch size = 32\n",
      "INFO:tensorflow:  Num steps = 22195\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (32, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (32, 128)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (32,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (32,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (32, 128)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30349, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
      "WARNING:tensorflow:From C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./output_dir/smishing/model.ckpt.\n",
      "ERROR:tensorflow:Error recorded from training_loop: 2 root error(s) found.\n",
      "  (0) Internal: Blas GEMM launch failed : a.shape=(4096, 2), b.shape=(2, 768), m=4096, n=768, k=2\n",
      "\t [[node bert/embeddings/MatMul (defined at C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n",
      "\t [[Mean/_1651]]\n",
      "  (1) Internal: Blas GEMM launch failed : a.shape=(4096, 2), b.shape=(2, 768), m=4096, n=768, k=2\n",
      "\t [[node bert/embeddings/MatMul (defined at C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "\n",
      "Original stack trace for 'bert/embeddings/MatMul':\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-326-fe5a959e0d41>\", line 11, in <module>\n",
      "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3030, in train\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1191, in _train_model_default\n",
      "    features, labels, ModeKeys.TRAIN, self.config)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 2857, in _call_model_fn\n",
      "    config)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1149, in _call_model_fn\n",
      "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3126, in _model_fn\n",
      "    features, labels, is_export_mode=is_export_mode)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 1663, in call_without_tpu\n",
      "    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 1994, in _call_model_fn\n",
      "    estimator_spec = self._model_fn(features=features, **kwargs)\n",
      "  File \"<ipython-input-281-477806206641>\", line 23, in model_fn\n",
      "    num_labels, use_one_hot_embeddings)\n",
      "  File \"<ipython-input-205-058da953979d>\", line 9, in create_model\n",
      "    use_one_hot_embeddings=use_one_hot_embeddings)\n",
      "  File \"<ipython-input-190-2a8b6553ec9d>\", line 46, in __init__\n",
      "    dropout_prob=config.hidden_dropout_prob)\n",
      "  File \"<ipython-input-199-200f5380971b>\", line 28, in embedding_postprocessor\n",
      "    token_type_embeddings = tf.matmul(one_hot_ids, token_type_table)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\", line 180, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 2754, in matmul\n",
      "    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6136, in mat_mul\n",
      "    name=name)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training_loop marked as finished\n",
      "WARNING:tensorflow:Reraising captured error\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "2 root error(s) found.\n  (0) Internal: Blas GEMM launch failed : a.shape=(4096, 2), b.shape=(2, 768), m=4096, n=768, k=2\n\t [[node bert/embeddings/MatMul (defined at C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\t [[Mean/_1651]]\n  (1) Internal: Blas GEMM launch failed : a.shape=(4096, 2), b.shape=(2, 768), m=4096, n=768, k=2\n\t [[node bert/embeddings/MatMul (defined at C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'bert/embeddings/MatMul':\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-326-fe5a959e0d41>\", line 11, in <module>\n    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3030, in train\n    saving_listeners=saving_listeners)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 370, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1161, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1191, in _train_model_default\n    features, labels, ModeKeys.TRAIN, self.config)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 2857, in _call_model_fn\n    config)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1149, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3126, in _model_fn\n    features, labels, is_export_mode=is_export_mode)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 1663, in call_without_tpu\n    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 1994, in _call_model_fn\n    estimator_spec = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-281-477806206641>\", line 23, in model_fn\n    num_labels, use_one_hot_embeddings)\n  File \"<ipython-input-205-058da953979d>\", line 9, in create_model\n    use_one_hot_embeddings=use_one_hot_embeddings)\n  File \"<ipython-input-190-2a8b6553ec9d>\", line 46, in __init__\n    dropout_prob=config.hidden_dropout_prob)\n  File \"<ipython-input-199-200f5380971b>\", line 28, in embedding_postprocessor\n    token_type_embeddings = tf.matmul(one_hot_ids, token_type_table)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 2754, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6136, in mat_mul\n    name=name)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Blas GEMM launch failed : a.shape=(4096, 2), b.shape=(2, 768), m=4096, n=768, k=2\n\t [[{{node bert/embeddings/MatMul}}]]\n\t [[Mean/_1651]]\n  (1) Internal: Blas GEMM launch failed : a.shape=(4096, 2), b.shape=(2, 768), m=4096, n=768, k=2\n\t [[{{node bert/embeddings/MatMul}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-326-fe5a959e0d41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     drop_remainder=True)\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m   3033\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3034\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training_loop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3035\u001b[1;33m       \u001b[0mrendezvous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[1;34m(self, timeout_sec)\u001b[0m\n\u001b[0;32m    134\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reraising captured error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    694\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m   3028\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m           saving_listeners=saving_listeners)\n\u001b[0m\u001b[0;32m   3031\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training_loop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1159\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1193\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1194\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1492\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1493\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1494\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1495\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m         run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1257\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m             run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1260\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m         logging.info(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1360\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    694\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1343\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1345\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1346\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1416\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m         run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Blas GEMM launch failed : a.shape=(4096, 2), b.shape=(2, 768), m=4096, n=768, k=2\n\t [[node bert/embeddings/MatMul (defined at C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n\t [[Mean/_1651]]\n  (1) Internal: Blas GEMM launch failed : a.shape=(4096, 2), b.shape=(2, 768), m=4096, n=768, k=2\n\t [[node bert/embeddings/MatMul (defined at C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'bert/embeddings/MatMul':\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-326-fe5a959e0d41>\", line 11, in <module>\n    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3030, in train\n    saving_listeners=saving_listeners)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 370, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1161, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1191, in _train_model_default\n    features, labels, ModeKeys.TRAIN, self.config)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 2857, in _call_model_fn\n    config)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1149, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 3126, in _model_fn\n    features, labels, is_export_mode=is_export_mode)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 1663, in call_without_tpu\n    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\tpu\\tpu_estimator.py\", line 1994, in _call_model_fn\n    estimator_spec = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-281-477806206641>\", line 23, in model_fn\n    num_labels, use_one_hot_embeddings)\n  File \"<ipython-input-205-058da953979d>\", line 9, in create_model\n    use_one_hot_embeddings=use_one_hot_embeddings)\n  File \"<ipython-input-190-2a8b6553ec9d>\", line 46, in __init__\n    dropout_prob=config.hidden_dropout_prob)\n  File \"<ipython-input-199-200f5380971b>\", line 28, in embedding_postprocessor\n    token_type_embeddings = tf.matmul(one_hot_ids, token_type_table)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\", line 2754, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\", line 6136, in mat_mul\n    name=name)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\jinma\\AppData\\Local\\Continuum\\anaconda3\\envs\\basic\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"***** Running training *****\")\n",
    "tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
    "tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n",
    "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "train_input_fn = file_based_input_fn_builder(\n",
    "    input_file=train_file,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=True,\n",
    "    drop_remainder=True)\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 부록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예시 샘플링 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tf.gfile.Open(os.path.join(dacon_path, \"train.tsv\"), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in reader:\n",
    "    lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_type = 'train'\n",
    "examples = []\n",
    "for (i, line) in enumerate(lines):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    guid = \"%s-%s\" % (set_type, i)\n",
    "    text_a = convert_to_unicode(line[2])\n",
    "    if set_type == 'test':\n",
    "        label = '0'\n",
    "    else:\n",
    "        label = convert_to_unicode(line[-1])\n",
    "    examples.append(\n",
    "        InputExample(guid=guid, text_a=text_a, label=label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
