{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow gpu 사용 가능한지 체크\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "\n",
      "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 14041509942375165425),\n",
      " _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 9106889769, 14255716566187076488)]\n"
     ]
    }
   ],
   "source": [
    "# 연산과 텐서가 어떤 디바이스에 배치되었는지 알아보기 위해\n",
    "# 세션을 만들 때 log_device_placement 옵션을 True로 설정 가능\n",
    "with tf.Session(config = tf.ConfigProto(log_device_placement=True)) as session:\n",
    "    pprint.pprint(session.list_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 디바이스 배치 로깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# 그래프 생성\n",
    "a = tf.constant([1., 2., 3., 4., 5., 6.], shape=[2, 3], name='a')\n",
    "b = tf.constant([1., 2., 3., 4., 5., 6.], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# log_device_placement을 True로 설정하여 세션을 만듦\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(c))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수동으로 디바이스에 배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# 그래프를 생성\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.constant([1., 2., 3., 4., 5., 6.], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1., 2., 3., 4., 5., 6.], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# log_device_placement를 True로 설정하여 세션을 만듦\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# op를 실행\n",
    "print(sess.run(c))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'bert' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!git clone https://github.com/google-research/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path += ['./bert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ./bert\\optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import python modules defined by BERT\n",
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import run_classifier_with_tfhub\n",
    "import tokenization\n",
    "\n",
    "# import tfhub\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments: 11개의 NLP Tasks\n",
    "1. MNLI(Multi-Genre Natural Language Inference): 두 개의 문장을 주고, 두번째 문장이 첫번째 문장과 같은 의미(entailment)인지, 모순(contradiction)이 있는지, 무관한(neutral) 의미인지 판단\n",
    "2. QQP(Quora Question Pair): 두 질문이 같은 의미의 질문인지 판단\n",
    "3. QNLI(Question Natural Language Inference): 질문과 문장을 주고, 그 문장에 답이 있으면 pos, 없으면 neg를 판단\n",
    "4. SST-2(Stanford Sentiment Treebank): movie review data에서 sentiment 분석(binary)\n",
    "5. CoLA(Corpus of Linguistic Acceptability): 문장의 문법이 맞는지 판단\n",
    "6. STS-B(Semantic Textual Similarity Benchmark): 두 문장의 sentiment가 같은지 판단\n",
    "7. MRPC(Microsoft Research Paraphrase corpus): 두 문장의 sentiment가 같은지 판단\n",
    "8. RTE(Recognizing Textual Entailment): MNLI와 비슷\n",
    "9. SQuAD 1.1(Stanford Question Answering Database): 질문을 보고 지문에서 answer text span을 찾아낸다. 즉, 정답의 시작점과 끝점을 찾아냄\n",
    "10. CoNLL Named Entity Recognition: 단어에 Person, Organization, Location, Miscellaneous, Other-Not named entity를 annotate\n",
    "11. SWAG(Situation with Adversarial Generations): video captioning DB에서 추출한 문장 다음에 올 문장으로 알맞은 것은? (4지선다형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'MRPC' #@param {type:\"string\"}\n",
    "assert TASK in ('MRPC', 'CoLA'), 'Only (MRPC, CoLA) are demonstrated here.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'download_glue_repo' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Download glue data.\n",
    "!git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MRPC...\n",
      "Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "!python download_glue_repo/download_glue_data.py --data_dir=glue_data --tasks=$TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Task data directory: glue_data\\MRPC *****\n",
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: 1687-9ECC\n",
      "\n",
      " C:\\workspace\\dacon문자스미싱\\glue_data\\MRPC 디렉터리\n",
      "\n",
      "2019-12-13  오후 04:37    <DIR>          .\n",
      "2019-12-13  오후 04:37    <DIR>          ..\n",
      "2019-12-27  오전 10:53           106,025 dev.tsv\n",
      "2019-12-27  오전 10:53             6,222 dev_ids.tsv\n",
      "2019-12-27  오전 10:53           441,275 msr_paraphrase_test.txt\n",
      "2019-12-27  오전 10:53         1,047,044 msr_paraphrase_train.txt\n",
      "2019-12-27  오전 10:53           447,061 test.tsv\n",
      "2019-12-27  오전 10:53           945,140 train.tsv\n",
      "               6개 파일           2,992,767 바이트\n",
      "               2개 디렉터리  277,213,212,672 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "TASK_DATA_DIR = 'glue_data\\\\' + TASK\n",
    "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
    "!dir $TASK_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = './bucket/' #@param {type:\"string\"}\n",
    "assert BUCKET, 'Must specify an existing GCS bucket name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './{}/bert-tfhub/models/{}'.format(BUCKET, TASK)\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: ././bucket//bert-tfhub/models/MRPC *****\n"
     ]
    }
   ],
   "source": [
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
    "\n",
    "# Available pretrained model checkpoints:\n",
    "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
    "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
    "#   cased_L-12_H-768_A-12: cased BERT large model\n",
    "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
    "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT_MODEL_HUB\t https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ./bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ./bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BERT_MODEL_HUB\\t', BERT_MODEL_HUB)\n",
    "with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature='tokenization_info',\n",
    "                                    as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "        vocab_file, do_lower_case = sess.run(\n",
    "            [tokenization_info['vocab_file'],\n",
    "             tokenization_info['do_lower_case']])\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'C:\\\\Users\\\\jinma\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\5a395eafef2a37bd9fc55d7f6ae676d2a134a838\\\\assets\\\\vocab.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'here',\n",
       " \"'\",\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'using',\n",
       " 'the',\n",
       " 'bert',\n",
       " 'token',\n",
       " '##izer']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ./bert\\run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ./bert\\run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 16\n",
    "EVAL_BATCH_SIZE = 8\n",
    "PREDICT_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "MAX_SEQ_LENGTH = 64\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 1000\n",
    "SAVE_SUMMARY_STEPS = 500\n",
    "\n",
    "processors = {\n",
    "  \"cola\": run_classifier.ColaProcessor,\n",
    "  \"mnli\": run_classifier.MnliProcessor,\n",
    "  \"mrpc\": run_classifier.MrpcProcessor,\n",
    "}\n",
    "processor = processors[TASK.lower()]()\n",
    "label_list = processor.get_labels()\n",
    "\n",
    "# Compute number of train and warmup steps from batch size\n",
    "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
    "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glue_data\\\\MRPC'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASK_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<run_classifier.InputExample at 0x135182e0358>,\n",
       " <run_classifier.InputExample at 0x135224bfb00>,\n",
       " <run_classifier.InputExample at 0x135224bfb70>,\n",
       " <run_classifier.InputExample at 0x135224bfbe0>,\n",
       " <run_classifier.InputExample at 0x135224bfc50>,\n",
       " <run_classifier.InputExample at 0x135224bfcc0>,\n",
       " <run_classifier.InputExample at 0x135224bfd30>,\n",
       " <run_classifier.InputExample at 0x135224bfda0>,\n",
       " <run_classifier.InputExample at 0x135224bfe10>,\n",
       " <run_classifier.InputExample at 0x135224bfe48>,\n",
       " <run_classifier.InputExample at 0x135224bfe80>,\n",
       " <run_classifier.InputExample at 0x135224bfeb8>,\n",
       " <run_classifier.InputExample at 0x135224bfef0>,\n",
       " <run_classifier.InputExample at 0x135224bff28>,\n",
       " <run_classifier.InputExample at 0x135224bff60>,\n",
       " <run_classifier.InputExample at 0x135224bff98>,\n",
       " <run_classifier.InputExample at 0x135224bffd0>,\n",
       " <run_classifier.InputExample at 0x135224c2048>,\n",
       " <run_classifier.InputExample at 0x135224c2080>,\n",
       " <run_classifier.InputExample at 0x135224c20b8>,\n",
       " <run_classifier.InputExample at 0x135224c20f0>,\n",
       " <run_classifier.InputExample at 0x135224c2128>,\n",
       " <run_classifier.InputExample at 0x135224c2160>,\n",
       " <run_classifier.InputExample at 0x135224c2198>,\n",
       " <run_classifier.InputExample at 0x135224c21d0>,\n",
       " <run_classifier.InputExample at 0x135224c2208>,\n",
       " <run_classifier.InputExample at 0x135224c2240>,\n",
       " <run_classifier.InputExample at 0x135224c2278>,\n",
       " <run_classifier.InputExample at 0x135224c22b0>,\n",
       " <run_classifier.InputExample at 0x135224c22e8>,\n",
       " <run_classifier.InputExample at 0x135224c2320>,\n",
       " <run_classifier.InputExample at 0x135224c2358>,\n",
       " <run_classifier.InputExample at 0x135224c2390>,\n",
       " <run_classifier.InputExample at 0x135224c23c8>,\n",
       " <run_classifier.InputExample at 0x135224c2400>,\n",
       " <run_classifier.InputExample at 0x135224c2438>,\n",
       " <run_classifier.InputExample at 0x135224c2470>,\n",
       " <run_classifier.InputExample at 0x135224c24a8>,\n",
       " <run_classifier.InputExample at 0x135224c24e0>,\n",
       " <run_classifier.InputExample at 0x135224c2518>,\n",
       " <run_classifier.InputExample at 0x135224c2550>,\n",
       " <run_classifier.InputExample at 0x135224c2588>,\n",
       " <run_classifier.InputExample at 0x135224c25c0>,\n",
       " <run_classifier.InputExample at 0x135224c25f8>,\n",
       " <run_classifier.InputExample at 0x135224c2630>,\n",
       " <run_classifier.InputExample at 0x135224c2668>,\n",
       " <run_classifier.InputExample at 0x135224c26a0>,\n",
       " <run_classifier.InputExample at 0x135224c26d8>,\n",
       " <run_classifier.InputExample at 0x135224c2710>,\n",
       " <run_classifier.InputExample at 0x135224c2748>,\n",
       " <run_classifier.InputExample at 0x135224c2780>,\n",
       " <run_classifier.InputExample at 0x135224c27b8>,\n",
       " <run_classifier.InputExample at 0x135224c27f0>,\n",
       " <run_classifier.InputExample at 0x135224c2828>,\n",
       " <run_classifier.InputExample at 0x135224c2860>,\n",
       " <run_classifier.InputExample at 0x135224c2898>,\n",
       " <run_classifier.InputExample at 0x135224c28d0>,\n",
       " <run_classifier.InputExample at 0x135224c2908>,\n",
       " <run_classifier.InputExample at 0x135224c2940>,\n",
       " <run_classifier.InputExample at 0x135224c2978>,\n",
       " <run_classifier.InputExample at 0x135224c29b0>,\n",
       " <run_classifier.InputExample at 0x135224c29e8>,\n",
       " <run_classifier.InputExample at 0x135224c2a20>,\n",
       " <run_classifier.InputExample at 0x135224c2a58>,\n",
       " <run_classifier.InputExample at 0x135224c2a90>,\n",
       " <run_classifier.InputExample at 0x135224c2ac8>,\n",
       " <run_classifier.InputExample at 0x135224c2b00>,\n",
       " <run_classifier.InputExample at 0x135224c2b38>,\n",
       " <run_classifier.InputExample at 0x135224c2b70>,\n",
       " <run_classifier.InputExample at 0x135224c2ba8>,\n",
       " <run_classifier.InputExample at 0x135224c2be0>,\n",
       " <run_classifier.InputExample at 0x135224c2c18>,\n",
       " <run_classifier.InputExample at 0x135224c2c50>,\n",
       " <run_classifier.InputExample at 0x135224c2c88>,\n",
       " <run_classifier.InputExample at 0x135224c2cc0>,\n",
       " <run_classifier.InputExample at 0x135224c2cf8>,\n",
       " <run_classifier.InputExample at 0x135224c2d30>,\n",
       " <run_classifier.InputExample at 0x135224c2d68>,\n",
       " <run_classifier.InputExample at 0x135224c2da0>,\n",
       " <run_classifier.InputExample at 0x135224c2dd8>,\n",
       " <run_classifier.InputExample at 0x135224c2e10>,\n",
       " <run_classifier.InputExample at 0x135224c2e48>,\n",
       " <run_classifier.InputExample at 0x135224c2e80>,\n",
       " <run_classifier.InputExample at 0x135224c2eb8>,\n",
       " <run_classifier.InputExample at 0x135224c2ef0>,\n",
       " <run_classifier.InputExample at 0x135224c2f28>,\n",
       " <run_classifier.InputExample at 0x135224c2f60>,\n",
       " <run_classifier.InputExample at 0x135224c2f98>,\n",
       " <run_classifier.InputExample at 0x135224c2fd0>,\n",
       " <run_classifier.InputExample at 0x135224c5048>,\n",
       " <run_classifier.InputExample at 0x135224c5080>,\n",
       " <run_classifier.InputExample at 0x135224c50b8>,\n",
       " <run_classifier.InputExample at 0x135224c50f0>,\n",
       " <run_classifier.InputExample at 0x135224c5128>,\n",
       " <run_classifier.InputExample at 0x135224c5160>,\n",
       " <run_classifier.InputExample at 0x135224c5198>,\n",
       " <run_classifier.InputExample at 0x135224c51d0>,\n",
       " <run_classifier.InputExample at 0x135224c5208>,\n",
       " <run_classifier.InputExample at 0x135224c5240>,\n",
       " <run_classifier.InputExample at 0x135224c5278>,\n",
       " <run_classifier.InputExample at 0x135224c52b0>,\n",
       " <run_classifier.InputExample at 0x135224c52e8>,\n",
       " <run_classifier.InputExample at 0x135224c5320>,\n",
       " <run_classifier.InputExample at 0x135224c5358>,\n",
       " <run_classifier.InputExample at 0x135224c5390>,\n",
       " <run_classifier.InputExample at 0x135224c53c8>,\n",
       " <run_classifier.InputExample at 0x135224c5400>,\n",
       " <run_classifier.InputExample at 0x135224c5438>,\n",
       " <run_classifier.InputExample at 0x135224c5470>,\n",
       " <run_classifier.InputExample at 0x135224c54a8>,\n",
       " <run_classifier.InputExample at 0x135224c54e0>,\n",
       " <run_classifier.InputExample at 0x135224c5518>,\n",
       " <run_classifier.InputExample at 0x135224c5550>,\n",
       " <run_classifier.InputExample at 0x135224c5588>,\n",
       " <run_classifier.InputExample at 0x135224c55c0>,\n",
       " <run_classifier.InputExample at 0x135224c55f8>,\n",
       " <run_classifier.InputExample at 0x135224c5630>,\n",
       " <run_classifier.InputExample at 0x135224c5668>,\n",
       " <run_classifier.InputExample at 0x135224c56a0>,\n",
       " <run_classifier.InputExample at 0x135224c56d8>,\n",
       " <run_classifier.InputExample at 0x135224c5710>,\n",
       " <run_classifier.InputExample at 0x135224c5748>,\n",
       " <run_classifier.InputExample at 0x135224c5780>,\n",
       " <run_classifier.InputExample at 0x135224c57b8>,\n",
       " <run_classifier.InputExample at 0x135224c57f0>,\n",
       " <run_classifier.InputExample at 0x135224c5828>,\n",
       " <run_classifier.InputExample at 0x135224c5860>,\n",
       " <run_classifier.InputExample at 0x135224c5898>,\n",
       " <run_classifier.InputExample at 0x135224c58d0>,\n",
       " <run_classifier.InputExample at 0x135224c5908>,\n",
       " <run_classifier.InputExample at 0x135224c5940>,\n",
       " <run_classifier.InputExample at 0x135224c5978>,\n",
       " <run_classifier.InputExample at 0x135224c59b0>,\n",
       " <run_classifier.InputExample at 0x135224c59e8>,\n",
       " <run_classifier.InputExample at 0x135224c5a20>,\n",
       " <run_classifier.InputExample at 0x135224c5a58>,\n",
       " <run_classifier.InputExample at 0x135224c5a90>,\n",
       " <run_classifier.InputExample at 0x135224c5ac8>,\n",
       " <run_classifier.InputExample at 0x135224c5b00>,\n",
       " <run_classifier.InputExample at 0x135224c5b38>,\n",
       " <run_classifier.InputExample at 0x135224c5b70>,\n",
       " <run_classifier.InputExample at 0x135224c5ba8>,\n",
       " <run_classifier.InputExample at 0x135224c5be0>,\n",
       " <run_classifier.InputExample at 0x135224c5c18>,\n",
       " <run_classifier.InputExample at 0x135224c5c50>,\n",
       " <run_classifier.InputExample at 0x135224c5c88>,\n",
       " <run_classifier.InputExample at 0x135224c5cc0>,\n",
       " <run_classifier.InputExample at 0x135224c5cf8>,\n",
       " <run_classifier.InputExample at 0x135224c5d30>,\n",
       " <run_classifier.InputExample at 0x135224c5d68>,\n",
       " <run_classifier.InputExample at 0x135224c5da0>,\n",
       " <run_classifier.InputExample at 0x135224c5dd8>,\n",
       " <run_classifier.InputExample at 0x135224c5e10>,\n",
       " <run_classifier.InputExample at 0x135224c5e48>,\n",
       " <run_classifier.InputExample at 0x135224c5e80>,\n",
       " <run_classifier.InputExample at 0x135224c5eb8>,\n",
       " <run_classifier.InputExample at 0x135224c5ef0>,\n",
       " <run_classifier.InputExample at 0x135224c5f28>,\n",
       " <run_classifier.InputExample at 0x135224c5f60>,\n",
       " <run_classifier.InputExample at 0x135224c5f98>,\n",
       " <run_classifier.InputExample at 0x135224c5fd0>,\n",
       " <run_classifier.InputExample at 0x135224c8048>,\n",
       " <run_classifier.InputExample at 0x135224c8080>,\n",
       " <run_classifier.InputExample at 0x135224c80b8>,\n",
       " <run_classifier.InputExample at 0x135224c80f0>,\n",
       " <run_classifier.InputExample at 0x135224c8128>,\n",
       " <run_classifier.InputExample at 0x135224c8160>,\n",
       " <run_classifier.InputExample at 0x135224c8198>,\n",
       " <run_classifier.InputExample at 0x135224c81d0>,\n",
       " <run_classifier.InputExample at 0x135224c8208>,\n",
       " <run_classifier.InputExample at 0x135224c8240>,\n",
       " <run_classifier.InputExample at 0x135224c8278>,\n",
       " <run_classifier.InputExample at 0x135224c82b0>,\n",
       " <run_classifier.InputExample at 0x135224c82e8>,\n",
       " <run_classifier.InputExample at 0x135224c8320>,\n",
       " <run_classifier.InputExample at 0x135224c8358>,\n",
       " <run_classifier.InputExample at 0x135224c8390>,\n",
       " <run_classifier.InputExample at 0x135224c83c8>,\n",
       " <run_classifier.InputExample at 0x135224c8400>,\n",
       " <run_classifier.InputExample at 0x135224c8438>,\n",
       " <run_classifier.InputExample at 0x135224c8470>,\n",
       " <run_classifier.InputExample at 0x135224c84a8>,\n",
       " <run_classifier.InputExample at 0x135224c84e0>,\n",
       " <run_classifier.InputExample at 0x135224c8518>,\n",
       " <run_classifier.InputExample at 0x135224c8550>,\n",
       " <run_classifier.InputExample at 0x135224c8588>,\n",
       " <run_classifier.InputExample at 0x135224c85c0>,\n",
       " <run_classifier.InputExample at 0x135224c85f8>,\n",
       " <run_classifier.InputExample at 0x135224c8630>,\n",
       " <run_classifier.InputExample at 0x135224c8668>,\n",
       " <run_classifier.InputExample at 0x135224c86a0>,\n",
       " <run_classifier.InputExample at 0x135224c86d8>,\n",
       " <run_classifier.InputExample at 0x135224c8710>,\n",
       " <run_classifier.InputExample at 0x135224c8748>,\n",
       " <run_classifier.InputExample at 0x135224c8780>,\n",
       " <run_classifier.InputExample at 0x135224c87b8>,\n",
       " <run_classifier.InputExample at 0x135224c87f0>,\n",
       " <run_classifier.InputExample at 0x135224c8828>,\n",
       " <run_classifier.InputExample at 0x135224c8860>,\n",
       " <run_classifier.InputExample at 0x135224c8898>,\n",
       " <run_classifier.InputExample at 0x135224c88d0>,\n",
       " <run_classifier.InputExample at 0x135224c8908>,\n",
       " <run_classifier.InputExample at 0x135224c8940>,\n",
       " <run_classifier.InputExample at 0x135224c8978>,\n",
       " <run_classifier.InputExample at 0x135224c89b0>,\n",
       " <run_classifier.InputExample at 0x135224c89e8>,\n",
       " <run_classifier.InputExample at 0x135224c8a20>,\n",
       " <run_classifier.InputExample at 0x135224c8a58>,\n",
       " <run_classifier.InputExample at 0x135224c8a90>,\n",
       " <run_classifier.InputExample at 0x135224c8ac8>,\n",
       " <run_classifier.InputExample at 0x135224c8b00>,\n",
       " <run_classifier.InputExample at 0x135224c8b38>,\n",
       " <run_classifier.InputExample at 0x135224c8b70>,\n",
       " <run_classifier.InputExample at 0x135224c8ba8>,\n",
       " <run_classifier.InputExample at 0x135224c8be0>,\n",
       " <run_classifier.InputExample at 0x135224c8c18>,\n",
       " <run_classifier.InputExample at 0x135224c8c50>,\n",
       " <run_classifier.InputExample at 0x135224c8c88>,\n",
       " <run_classifier.InputExample at 0x135224c8cc0>,\n",
       " <run_classifier.InputExample at 0x135224c8cf8>,\n",
       " <run_classifier.InputExample at 0x135224c8d30>,\n",
       " <run_classifier.InputExample at 0x135224c8d68>,\n",
       " <run_classifier.InputExample at 0x135224c8da0>,\n",
       " <run_classifier.InputExample at 0x135224c8dd8>,\n",
       " <run_classifier.InputExample at 0x135224c8e10>,\n",
       " <run_classifier.InputExample at 0x135224c8e48>,\n",
       " <run_classifier.InputExample at 0x135224c8e80>,\n",
       " <run_classifier.InputExample at 0x135224c8eb8>,\n",
       " <run_classifier.InputExample at 0x135224c8ef0>,\n",
       " <run_classifier.InputExample at 0x135224c8f28>,\n",
       " <run_classifier.InputExample at 0x135224c8f60>,\n",
       " <run_classifier.InputExample at 0x135224c8f98>,\n",
       " <run_classifier.InputExample at 0x135224c8fd0>,\n",
       " <run_classifier.InputExample at 0x135224cc048>,\n",
       " <run_classifier.InputExample at 0x135224cc080>,\n",
       " <run_classifier.InputExample at 0x135224cc0b8>,\n",
       " <run_classifier.InputExample at 0x135224cc0f0>,\n",
       " <run_classifier.InputExample at 0x135224cc128>,\n",
       " <run_classifier.InputExample at 0x135224cc160>,\n",
       " <run_classifier.InputExample at 0x135224cc198>,\n",
       " <run_classifier.InputExample at 0x135224cc1d0>,\n",
       " <run_classifier.InputExample at 0x135224cc208>,\n",
       " <run_classifier.InputExample at 0x135224cc240>,\n",
       " <run_classifier.InputExample at 0x135224cc278>,\n",
       " <run_classifier.InputExample at 0x135224cc2b0>,\n",
       " <run_classifier.InputExample at 0x135224cc2e8>,\n",
       " <run_classifier.InputExample at 0x135224cc320>,\n",
       " <run_classifier.InputExample at 0x135224cc358>,\n",
       " <run_classifier.InputExample at 0x135224cc390>,\n",
       " <run_classifier.InputExample at 0x135224cc3c8>,\n",
       " <run_classifier.InputExample at 0x135224cc400>,\n",
       " <run_classifier.InputExample at 0x135224cc438>,\n",
       " <run_classifier.InputExample at 0x135224cc470>,\n",
       " <run_classifier.InputExample at 0x135224cc4a8>,\n",
       " <run_classifier.InputExample at 0x135224cc4e0>,\n",
       " <run_classifier.InputExample at 0x135224cc518>,\n",
       " <run_classifier.InputExample at 0x135224cc550>,\n",
       " <run_classifier.InputExample at 0x135224cc588>,\n",
       " <run_classifier.InputExample at 0x135224cc5c0>,\n",
       " <run_classifier.InputExample at 0x135224cc5f8>,\n",
       " <run_classifier.InputExample at 0x135224cc630>,\n",
       " <run_classifier.InputExample at 0x135224cc668>,\n",
       " <run_classifier.InputExample at 0x135224cc6a0>,\n",
       " <run_classifier.InputExample at 0x135224cc6d8>,\n",
       " <run_classifier.InputExample at 0x135224cc710>,\n",
       " <run_classifier.InputExample at 0x135224cc748>,\n",
       " <run_classifier.InputExample at 0x135224cc780>,\n",
       " <run_classifier.InputExample at 0x135224cc7b8>,\n",
       " <run_classifier.InputExample at 0x135224cc7f0>,\n",
       " <run_classifier.InputExample at 0x135224cc828>,\n",
       " <run_classifier.InputExample at 0x135224cc860>,\n",
       " <run_classifier.InputExample at 0x135224cc898>,\n",
       " <run_classifier.InputExample at 0x135224cc8d0>,\n",
       " <run_classifier.InputExample at 0x135224cc908>,\n",
       " <run_classifier.InputExample at 0x135224cc940>,\n",
       " <run_classifier.InputExample at 0x135224cc978>,\n",
       " <run_classifier.InputExample at 0x135224cc9b0>,\n",
       " <run_classifier.InputExample at 0x135224cc9e8>,\n",
       " <run_classifier.InputExample at 0x135224cca20>,\n",
       " <run_classifier.InputExample at 0x135224cca58>,\n",
       " <run_classifier.InputExample at 0x135224cca90>,\n",
       " <run_classifier.InputExample at 0x135224ccac8>,\n",
       " <run_classifier.InputExample at 0x135224ccb00>,\n",
       " <run_classifier.InputExample at 0x135224ccb38>,\n",
       " <run_classifier.InputExample at 0x135224ccb70>,\n",
       " <run_classifier.InputExample at 0x135224ccba8>,\n",
       " <run_classifier.InputExample at 0x135224ccbe0>,\n",
       " <run_classifier.InputExample at 0x135224ccc18>,\n",
       " <run_classifier.InputExample at 0x135224ccc50>,\n",
       " <run_classifier.InputExample at 0x135224ccc88>,\n",
       " <run_classifier.InputExample at 0x135224cccc0>,\n",
       " <run_classifier.InputExample at 0x135224cccf8>,\n",
       " <run_classifier.InputExample at 0x135224ccd30>,\n",
       " <run_classifier.InputExample at 0x135224ccd68>,\n",
       " <run_classifier.InputExample at 0x135224ccda0>,\n",
       " <run_classifier.InputExample at 0x135224ccdd8>,\n",
       " <run_classifier.InputExample at 0x135224cce10>,\n",
       " <run_classifier.InputExample at 0x135224cce48>,\n",
       " <run_classifier.InputExample at 0x135224cce80>,\n",
       " <run_classifier.InputExample at 0x135224cceb8>,\n",
       " <run_classifier.InputExample at 0x135224ccef0>,\n",
       " <run_classifier.InputExample at 0x135224ccf28>,\n",
       " <run_classifier.InputExample at 0x135224ccf60>,\n",
       " <run_classifier.InputExample at 0x135224ccf98>,\n",
       " <run_classifier.InputExample at 0x135224ccfd0>,\n",
       " <run_classifier.InputExample at 0x135224cf048>,\n",
       " <run_classifier.InputExample at 0x135224cf080>,\n",
       " <run_classifier.InputExample at 0x135224cf0b8>,\n",
       " <run_classifier.InputExample at 0x135224cf0f0>,\n",
       " <run_classifier.InputExample at 0x135224cf128>,\n",
       " <run_classifier.InputExample at 0x135224cf160>,\n",
       " <run_classifier.InputExample at 0x135224cf198>,\n",
       " <run_classifier.InputExample at 0x135224cf1d0>,\n",
       " <run_classifier.InputExample at 0x135224cf208>,\n",
       " <run_classifier.InputExample at 0x135224cf240>,\n",
       " <run_classifier.InputExample at 0x135224cf278>,\n",
       " <run_classifier.InputExample at 0x135224cf2b0>,\n",
       " <run_classifier.InputExample at 0x135224cf2e8>,\n",
       " <run_classifier.InputExample at 0x135224cf320>,\n",
       " <run_classifier.InputExample at 0x135224cf358>,\n",
       " <run_classifier.InputExample at 0x135224cf390>,\n",
       " <run_classifier.InputExample at 0x135224cf3c8>,\n",
       " <run_classifier.InputExample at 0x135224cf400>,\n",
       " <run_classifier.InputExample at 0x135224cf438>,\n",
       " <run_classifier.InputExample at 0x135224cf470>,\n",
       " <run_classifier.InputExample at 0x135224cf4a8>,\n",
       " <run_classifier.InputExample at 0x135224cf4e0>,\n",
       " <run_classifier.InputExample at 0x135224cf518>,\n",
       " <run_classifier.InputExample at 0x135224cf550>,\n",
       " <run_classifier.InputExample at 0x135224cf588>,\n",
       " <run_classifier.InputExample at 0x135224cf5c0>,\n",
       " <run_classifier.InputExample at 0x135224cf5f8>,\n",
       " <run_classifier.InputExample at 0x135224cf630>,\n",
       " <run_classifier.InputExample at 0x135224cf668>,\n",
       " <run_classifier.InputExample at 0x135224cf6a0>,\n",
       " <run_classifier.InputExample at 0x135224cf6d8>,\n",
       " <run_classifier.InputExample at 0x135224cf710>,\n",
       " <run_classifier.InputExample at 0x135224cf748>,\n",
       " <run_classifier.InputExample at 0x135224cf780>,\n",
       " <run_classifier.InputExample at 0x135224cf7b8>,\n",
       " <run_classifier.InputExample at 0x135224cf7f0>,\n",
       " <run_classifier.InputExample at 0x135224cf828>,\n",
       " <run_classifier.InputExample at 0x135224cf860>,\n",
       " <run_classifier.InputExample at 0x135224cf898>,\n",
       " <run_classifier.InputExample at 0x135224cf8d0>,\n",
       " <run_classifier.InputExample at 0x135224cf908>,\n",
       " <run_classifier.InputExample at 0x135224cf940>,\n",
       " <run_classifier.InputExample at 0x135224cf978>,\n",
       " <run_classifier.InputExample at 0x135224cf9b0>,\n",
       " <run_classifier.InputExample at 0x135224cf9e8>,\n",
       " <run_classifier.InputExample at 0x135224cfa20>,\n",
       " <run_classifier.InputExample at 0x135224cfa58>,\n",
       " <run_classifier.InputExample at 0x135224cfa90>,\n",
       " <run_classifier.InputExample at 0x135224cfac8>,\n",
       " <run_classifier.InputExample at 0x135224cfb00>,\n",
       " <run_classifier.InputExample at 0x135224cfb38>,\n",
       " <run_classifier.InputExample at 0x135224cfb70>,\n",
       " <run_classifier.InputExample at 0x135224cfba8>,\n",
       " <run_classifier.InputExample at 0x135224cfbe0>,\n",
       " <run_classifier.InputExample at 0x135224cfc18>,\n",
       " <run_classifier.InputExample at 0x135224cfc50>,\n",
       " <run_classifier.InputExample at 0x135224cfc88>,\n",
       " <run_classifier.InputExample at 0x135224cfcc0>,\n",
       " <run_classifier.InputExample at 0x135224cfcf8>,\n",
       " <run_classifier.InputExample at 0x135224cfd30>,\n",
       " <run_classifier.InputExample at 0x135224cfd68>,\n",
       " <run_classifier.InputExample at 0x135224cfda0>,\n",
       " <run_classifier.InputExample at 0x135224cfdd8>,\n",
       " <run_classifier.InputExample at 0x135224cfe10>,\n",
       " <run_classifier.InputExample at 0x135224cfe48>,\n",
       " <run_classifier.InputExample at 0x135224cfe80>,\n",
       " <run_classifier.InputExample at 0x135224cfeb8>,\n",
       " <run_classifier.InputExample at 0x135224cfef0>,\n",
       " <run_classifier.InputExample at 0x135224cff28>,\n",
       " <run_classifier.InputExample at 0x135224cff60>,\n",
       " <run_classifier.InputExample at 0x135224cff98>,\n",
       " <run_classifier.InputExample at 0x135224cffd0>,\n",
       " <run_classifier.InputExample at 0x135224d5048>,\n",
       " <run_classifier.InputExample at 0x135224d5080>,\n",
       " <run_classifier.InputExample at 0x135224d50b8>,\n",
       " <run_classifier.InputExample at 0x135224d50f0>,\n",
       " <run_classifier.InputExample at 0x135224d5128>,\n",
       " <run_classifier.InputExample at 0x135224d5160>,\n",
       " <run_classifier.InputExample at 0x135224d5198>,\n",
       " <run_classifier.InputExample at 0x135224d51d0>,\n",
       " <run_classifier.InputExample at 0x135224d5208>,\n",
       " <run_classifier.InputExample at 0x135224d5240>,\n",
       " <run_classifier.InputExample at 0x135224d5278>,\n",
       " <run_classifier.InputExample at 0x135224d52b0>,\n",
       " <run_classifier.InputExample at 0x135224d52e8>,\n",
       " <run_classifier.InputExample at 0x135224d5320>,\n",
       " <run_classifier.InputExample at 0x135224d5358>,\n",
       " <run_classifier.InputExample at 0x135224d5390>,\n",
       " <run_classifier.InputExample at 0x135224d53c8>,\n",
       " <run_classifier.InputExample at 0x135224d5400>,\n",
       " <run_classifier.InputExample at 0x135224d5438>,\n",
       " <run_classifier.InputExample at 0x135224d5470>,\n",
       " <run_classifier.InputExample at 0x135224d54a8>,\n",
       " <run_classifier.InputExample at 0x135224d54e0>,\n",
       " <run_classifier.InputExample at 0x135224d5518>,\n",
       " <run_classifier.InputExample at 0x135224d5550>,\n",
       " <run_classifier.InputExample at 0x135224d5588>,\n",
       " <run_classifier.InputExample at 0x135224d55c0>,\n",
       " <run_classifier.InputExample at 0x135224d55f8>,\n",
       " <run_classifier.InputExample at 0x135224d5630>,\n",
       " <run_classifier.InputExample at 0x135224d5668>,\n",
       " <run_classifier.InputExample at 0x135224d56a0>,\n",
       " <run_classifier.InputExample at 0x135224d56d8>,\n",
       " <run_classifier.InputExample at 0x135224d5710>,\n",
       " <run_classifier.InputExample at 0x135224d5748>,\n",
       " <run_classifier.InputExample at 0x135224d5780>,\n",
       " <run_classifier.InputExample at 0x135224d57b8>,\n",
       " <run_classifier.InputExample at 0x135224d57f0>,\n",
       " <run_classifier.InputExample at 0x135224d5828>,\n",
       " <run_classifier.InputExample at 0x135224d5860>,\n",
       " <run_classifier.InputExample at 0x135224d5898>,\n",
       " <run_classifier.InputExample at 0x135224d58d0>,\n",
       " <run_classifier.InputExample at 0x135224d5908>,\n",
       " <run_classifier.InputExample at 0x135224d5940>,\n",
       " <run_classifier.InputExample at 0x135224d5978>,\n",
       " <run_classifier.InputExample at 0x135224d59b0>,\n",
       " <run_classifier.InputExample at 0x135224d59e8>,\n",
       " <run_classifier.InputExample at 0x135224d5a20>,\n",
       " <run_classifier.InputExample at 0x135224d5a58>,\n",
       " <run_classifier.InputExample at 0x135224d5a90>,\n",
       " <run_classifier.InputExample at 0x135224d5ac8>,\n",
       " <run_classifier.InputExample at 0x135224d5b00>,\n",
       " <run_classifier.InputExample at 0x135224d5b38>,\n",
       " <run_classifier.InputExample at 0x135224d5b70>,\n",
       " <run_classifier.InputExample at 0x135224d5ba8>,\n",
       " <run_classifier.InputExample at 0x135224d5be0>,\n",
       " <run_classifier.InputExample at 0x135224d5c18>,\n",
       " <run_classifier.InputExample at 0x135224d5c50>,\n",
       " <run_classifier.InputExample at 0x135224d5c88>,\n",
       " <run_classifier.InputExample at 0x135224d5cc0>,\n",
       " <run_classifier.InputExample at 0x135224d5cf8>,\n",
       " <run_classifier.InputExample at 0x135224d5d30>,\n",
       " <run_classifier.InputExample at 0x135224d5d68>,\n",
       " <run_classifier.InputExample at 0x135224d5da0>,\n",
       " <run_classifier.InputExample at 0x135224d5dd8>,\n",
       " <run_classifier.InputExample at 0x135224d5e10>,\n",
       " <run_classifier.InputExample at 0x135224d5e48>,\n",
       " <run_classifier.InputExample at 0x135224d5e80>,\n",
       " <run_classifier.InputExample at 0x135224d5eb8>,\n",
       " <run_classifier.InputExample at 0x135224d5ef0>,\n",
       " <run_classifier.InputExample at 0x135224d5f28>,\n",
       " <run_classifier.InputExample at 0x135224d5f60>,\n",
       " <run_classifier.InputExample at 0x135224d5f98>,\n",
       " <run_classifier.InputExample at 0x135224d5fd0>,\n",
       " <run_classifier.InputExample at 0x135224d9048>,\n",
       " <run_classifier.InputExample at 0x135224d9080>,\n",
       " <run_classifier.InputExample at 0x135224d90b8>,\n",
       " <run_classifier.InputExample at 0x135224d90f0>,\n",
       " <run_classifier.InputExample at 0x135224d9128>,\n",
       " <run_classifier.InputExample at 0x135224d9160>,\n",
       " <run_classifier.InputExample at 0x135224d9198>,\n",
       " <run_classifier.InputExample at 0x135224d91d0>,\n",
       " <run_classifier.InputExample at 0x135224d9208>,\n",
       " <run_classifier.InputExample at 0x135224d9240>,\n",
       " <run_classifier.InputExample at 0x135224d9278>,\n",
       " <run_classifier.InputExample at 0x135224d92b0>,\n",
       " <run_classifier.InputExample at 0x135224d92e8>,\n",
       " <run_classifier.InputExample at 0x135224d9320>,\n",
       " <run_classifier.InputExample at 0x135224d9358>,\n",
       " <run_classifier.InputExample at 0x135224d9390>,\n",
       " <run_classifier.InputExample at 0x135224d93c8>,\n",
       " <run_classifier.InputExample at 0x135224d9400>,\n",
       " <run_classifier.InputExample at 0x135224d9438>,\n",
       " <run_classifier.InputExample at 0x135224d9470>,\n",
       " <run_classifier.InputExample at 0x135224d94a8>,\n",
       " <run_classifier.InputExample at 0x135224d94e0>,\n",
       " <run_classifier.InputExample at 0x135224d9518>,\n",
       " <run_classifier.InputExample at 0x135224d9550>,\n",
       " <run_classifier.InputExample at 0x135224d9588>,\n",
       " <run_classifier.InputExample at 0x135224d95c0>,\n",
       " <run_classifier.InputExample at 0x135224d95f8>,\n",
       " <run_classifier.InputExample at 0x135224d9630>,\n",
       " <run_classifier.InputExample at 0x135224d9668>,\n",
       " <run_classifier.InputExample at 0x135224d96a0>,\n",
       " <run_classifier.InputExample at 0x135224d96d8>,\n",
       " <run_classifier.InputExample at 0x135224d9710>,\n",
       " <run_classifier.InputExample at 0x135224d9748>,\n",
       " <run_classifier.InputExample at 0x135224d9780>,\n",
       " <run_classifier.InputExample at 0x135224d97b8>,\n",
       " <run_classifier.InputExample at 0x135224d97f0>,\n",
       " <run_classifier.InputExample at 0x135224d9828>,\n",
       " <run_classifier.InputExample at 0x135224d9860>,\n",
       " <run_classifier.InputExample at 0x135224d9898>,\n",
       " <run_classifier.InputExample at 0x135224d98d0>,\n",
       " <run_classifier.InputExample at 0x135224d9908>,\n",
       " <run_classifier.InputExample at 0x135224d9940>,\n",
       " <run_classifier.InputExample at 0x135224d9978>,\n",
       " <run_classifier.InputExample at 0x135224d99b0>,\n",
       " <run_classifier.InputExample at 0x135224d99e8>,\n",
       " <run_classifier.InputExample at 0x135224d9a20>,\n",
       " <run_classifier.InputExample at 0x135224d9a58>,\n",
       " <run_classifier.InputExample at 0x135224d9a90>,\n",
       " <run_classifier.InputExample at 0x135224d9ac8>,\n",
       " <run_classifier.InputExample at 0x135224d9b00>,\n",
       " <run_classifier.InputExample at 0x135224d9b38>,\n",
       " <run_classifier.InputExample at 0x135224d9b70>,\n",
       " <run_classifier.InputExample at 0x135224d9ba8>,\n",
       " <run_classifier.InputExample at 0x135224d9be0>,\n",
       " <run_classifier.InputExample at 0x135224d9c18>,\n",
       " <run_classifier.InputExample at 0x135224d9c50>,\n",
       " <run_classifier.InputExample at 0x135224d9c88>,\n",
       " <run_classifier.InputExample at 0x135224d9cc0>,\n",
       " <run_classifier.InputExample at 0x135224d9cf8>,\n",
       " <run_classifier.InputExample at 0x135224d9d30>,\n",
       " <run_classifier.InputExample at 0x135224d9d68>,\n",
       " <run_classifier.InputExample at 0x135224d9da0>,\n",
       " <run_classifier.InputExample at 0x135224d9dd8>,\n",
       " <run_classifier.InputExample at 0x135224d9e10>,\n",
       " <run_classifier.InputExample at 0x135224d9e48>,\n",
       " <run_classifier.InputExample at 0x135224d9e80>,\n",
       " <run_classifier.InputExample at 0x135224d9eb8>,\n",
       " <run_classifier.InputExample at 0x135224d9ef0>,\n",
       " <run_classifier.InputExample at 0x135224d9f28>,\n",
       " <run_classifier.InputExample at 0x135224d9f60>,\n",
       " <run_classifier.InputExample at 0x135224d9f98>,\n",
       " <run_classifier.InputExample at 0x135224d9fd0>,\n",
       " <run_classifier.InputExample at 0x135224dc048>,\n",
       " <run_classifier.InputExample at 0x135224dc080>,\n",
       " <run_classifier.InputExample at 0x135224dc0b8>,\n",
       " <run_classifier.InputExample at 0x135224dc0f0>,\n",
       " <run_classifier.InputExample at 0x135224dc128>,\n",
       " <run_classifier.InputExample at 0x135224dc160>,\n",
       " <run_classifier.InputExample at 0x135224dc198>,\n",
       " <run_classifier.InputExample at 0x135224dc1d0>,\n",
       " <run_classifier.InputExample at 0x135224dc208>,\n",
       " <run_classifier.InputExample at 0x135224dc240>,\n",
       " <run_classifier.InputExample at 0x135224dc278>,\n",
       " <run_classifier.InputExample at 0x135224dc2b0>,\n",
       " <run_classifier.InputExample at 0x135224dc2e8>,\n",
       " <run_classifier.InputExample at 0x135224dc320>,\n",
       " <run_classifier.InputExample at 0x135224dc358>,\n",
       " <run_classifier.InputExample at 0x135224dc390>,\n",
       " <run_classifier.InputExample at 0x135224dc3c8>,\n",
       " <run_classifier.InputExample at 0x135224dc400>,\n",
       " <run_classifier.InputExample at 0x135224dc438>,\n",
       " <run_classifier.InputExample at 0x135224dc470>,\n",
       " <run_classifier.InputExample at 0x135224dc4a8>,\n",
       " <run_classifier.InputExample at 0x135224dc4e0>,\n",
       " <run_classifier.InputExample at 0x135224dc518>,\n",
       " <run_classifier.InputExample at 0x135224dc550>,\n",
       " <run_classifier.InputExample at 0x135224dc588>,\n",
       " <run_classifier.InputExample at 0x135224dc5c0>,\n",
       " <run_classifier.InputExample at 0x135224dc5f8>,\n",
       " <run_classifier.InputExample at 0x135224dc630>,\n",
       " <run_classifier.InputExample at 0x135224dc668>,\n",
       " <run_classifier.InputExample at 0x135224dc6a0>,\n",
       " <run_classifier.InputExample at 0x135224dc6d8>,\n",
       " <run_classifier.InputExample at 0x135224dc710>,\n",
       " <run_classifier.InputExample at 0x135224dc748>,\n",
       " <run_classifier.InputExample at 0x135224dc780>,\n",
       " <run_classifier.InputExample at 0x135224dc7b8>,\n",
       " <run_classifier.InputExample at 0x135224dc7f0>,\n",
       " <run_classifier.InputExample at 0x135224dc828>,\n",
       " <run_classifier.InputExample at 0x135224dc860>,\n",
       " <run_classifier.InputExample at 0x135224dc898>,\n",
       " <run_classifier.InputExample at 0x135224dc8d0>,\n",
       " <run_classifier.InputExample at 0x135224dc908>,\n",
       " <run_classifier.InputExample at 0x135224dc940>,\n",
       " <run_classifier.InputExample at 0x135224dc978>,\n",
       " <run_classifier.InputExample at 0x135224dc9b0>,\n",
       " <run_classifier.InputExample at 0x135224dc9e8>,\n",
       " <run_classifier.InputExample at 0x135224dca20>,\n",
       " <run_classifier.InputExample at 0x135224dca58>,\n",
       " <run_classifier.InputExample at 0x135224dca90>,\n",
       " <run_classifier.InputExample at 0x135224dcac8>,\n",
       " <run_classifier.InputExample at 0x135224dcb00>,\n",
       " <run_classifier.InputExample at 0x135224dcb38>,\n",
       " <run_classifier.InputExample at 0x135224dcb70>,\n",
       " <run_classifier.InputExample at 0x135224dcba8>,\n",
       " <run_classifier.InputExample at 0x135224dcbe0>,\n",
       " <run_classifier.InputExample at 0x135224dcc18>,\n",
       " <run_classifier.InputExample at 0x135224dcc50>,\n",
       " <run_classifier.InputExample at 0x135224dcc88>,\n",
       " <run_classifier.InputExample at 0x135224dccc0>,\n",
       " <run_classifier.InputExample at 0x135224dccf8>,\n",
       " <run_classifier.InputExample at 0x135224dcd30>,\n",
       " <run_classifier.InputExample at 0x135224dcd68>,\n",
       " <run_classifier.InputExample at 0x135224dcda0>,\n",
       " <run_classifier.InputExample at 0x135224dcdd8>,\n",
       " <run_classifier.InputExample at 0x135224dce10>,\n",
       " <run_classifier.InputExample at 0x135224dce48>,\n",
       " <run_classifier.InputExample at 0x135224dce80>,\n",
       " <run_classifier.InputExample at 0x135224dceb8>,\n",
       " <run_classifier.InputExample at 0x135224dcef0>,\n",
       " <run_classifier.InputExample at 0x135224dcf28>,\n",
       " <run_classifier.InputExample at 0x135224dcf60>,\n",
       " <run_classifier.InputExample at 0x135224dcf98>,\n",
       " <run_classifier.InputExample at 0x135224dcfd0>,\n",
       " <run_classifier.InputExample at 0x135224e1048>,\n",
       " <run_classifier.InputExample at 0x135224e1080>,\n",
       " <run_classifier.InputExample at 0x135224e10b8>,\n",
       " <run_classifier.InputExample at 0x135224e10f0>,\n",
       " <run_classifier.InputExample at 0x135224e1128>,\n",
       " <run_classifier.InputExample at 0x135224e1160>,\n",
       " <run_classifier.InputExample at 0x135224e1198>,\n",
       " <run_classifier.InputExample at 0x135224e11d0>,\n",
       " <run_classifier.InputExample at 0x135224e1208>,\n",
       " <run_classifier.InputExample at 0x135224e1240>,\n",
       " <run_classifier.InputExample at 0x135224e1278>,\n",
       " <run_classifier.InputExample at 0x135224e12b0>,\n",
       " <run_classifier.InputExample at 0x135224e12e8>,\n",
       " <run_classifier.InputExample at 0x135224e1320>,\n",
       " <run_classifier.InputExample at 0x135224e1358>,\n",
       " <run_classifier.InputExample at 0x135224e1390>,\n",
       " <run_classifier.InputExample at 0x135224e13c8>,\n",
       " <run_classifier.InputExample at 0x135224e1400>,\n",
       " <run_classifier.InputExample at 0x135224e1438>,\n",
       " <run_classifier.InputExample at 0x135224e1470>,\n",
       " <run_classifier.InputExample at 0x135224e14a8>,\n",
       " <run_classifier.InputExample at 0x135224e14e0>,\n",
       " <run_classifier.InputExample at 0x135224e1518>,\n",
       " <run_classifier.InputExample at 0x135224e1550>,\n",
       " <run_classifier.InputExample at 0x135224e1588>,\n",
       " <run_classifier.InputExample at 0x135224e15c0>,\n",
       " <run_classifier.InputExample at 0x135224e15f8>,\n",
       " <run_classifier.InputExample at 0x135224e1630>,\n",
       " <run_classifier.InputExample at 0x135224e1668>,\n",
       " <run_classifier.InputExample at 0x135224e16a0>,\n",
       " <run_classifier.InputExample at 0x135224e16d8>,\n",
       " <run_classifier.InputExample at 0x135224e1710>,\n",
       " <run_classifier.InputExample at 0x135224e1748>,\n",
       " <run_classifier.InputExample at 0x135224e1780>,\n",
       " <run_classifier.InputExample at 0x135224e17b8>,\n",
       " <run_classifier.InputExample at 0x135224e17f0>,\n",
       " <run_classifier.InputExample at 0x135224e1828>,\n",
       " <run_classifier.InputExample at 0x135224e1860>,\n",
       " <run_classifier.InputExample at 0x135224e1898>,\n",
       " <run_classifier.InputExample at 0x135224e18d0>,\n",
       " <run_classifier.InputExample at 0x135224e1908>,\n",
       " <run_classifier.InputExample at 0x135224e1940>,\n",
       " <run_classifier.InputExample at 0x135224e1978>,\n",
       " <run_classifier.InputExample at 0x135224e19b0>,\n",
       " <run_classifier.InputExample at 0x135224e19e8>,\n",
       " <run_classifier.InputExample at 0x135224e1a20>,\n",
       " <run_classifier.InputExample at 0x135224e1a58>,\n",
       " <run_classifier.InputExample at 0x135224e1a90>,\n",
       " <run_classifier.InputExample at 0x135224e1ac8>,\n",
       " <run_classifier.InputExample at 0x135224e1b00>,\n",
       " <run_classifier.InputExample at 0x135224e1b38>,\n",
       " <run_classifier.InputExample at 0x135224e1b70>,\n",
       " <run_classifier.InputExample at 0x135224e1ba8>,\n",
       " <run_classifier.InputExample at 0x135224e1be0>,\n",
       " <run_classifier.InputExample at 0x135224e1c18>,\n",
       " <run_classifier.InputExample at 0x135224e1c50>,\n",
       " <run_classifier.InputExample at 0x135224e1c88>,\n",
       " <run_classifier.InputExample at 0x135224e1cc0>,\n",
       " <run_classifier.InputExample at 0x135224e1cf8>,\n",
       " <run_classifier.InputExample at 0x135224e1d30>,\n",
       " <run_classifier.InputExample at 0x135224e1d68>,\n",
       " <run_classifier.InputExample at 0x135224e1da0>,\n",
       " <run_classifier.InputExample at 0x135224e1dd8>,\n",
       " <run_classifier.InputExample at 0x135224e1e10>,\n",
       " <run_classifier.InputExample at 0x135224e1e48>,\n",
       " <run_classifier.InputExample at 0x135224e1e80>,\n",
       " <run_classifier.InputExample at 0x135224e1eb8>,\n",
       " <run_classifier.InputExample at 0x135224e1ef0>,\n",
       " <run_classifier.InputExample at 0x135224e1f28>,\n",
       " <run_classifier.InputExample at 0x135224e1f60>,\n",
       " <run_classifier.InputExample at 0x135224e1f98>,\n",
       " <run_classifier.InputExample at 0x135224e1fd0>,\n",
       " <run_classifier.InputExample at 0x135224e5048>,\n",
       " <run_classifier.InputExample at 0x135224e5080>,\n",
       " <run_classifier.InputExample at 0x135224e50b8>,\n",
       " <run_classifier.InputExample at 0x135224e50f0>,\n",
       " <run_classifier.InputExample at 0x135224e5128>,\n",
       " <run_classifier.InputExample at 0x135224e5160>,\n",
       " <run_classifier.InputExample at 0x135224e5198>,\n",
       " <run_classifier.InputExample at 0x135224e51d0>,\n",
       " <run_classifier.InputExample at 0x135224e5208>,\n",
       " <run_classifier.InputExample at 0x135224e5240>,\n",
       " <run_classifier.InputExample at 0x135224e5278>,\n",
       " <run_classifier.InputExample at 0x135224e52b0>,\n",
       " <run_classifier.InputExample at 0x135224e52e8>,\n",
       " <run_classifier.InputExample at 0x135224e5320>,\n",
       " <run_classifier.InputExample at 0x135224e5358>,\n",
       " <run_classifier.InputExample at 0x135224e5390>,\n",
       " <run_classifier.InputExample at 0x135224e53c8>,\n",
       " <run_classifier.InputExample at 0x135224e5400>,\n",
       " <run_classifier.InputExample at 0x135224e5438>,\n",
       " <run_classifier.InputExample at 0x135224e5470>,\n",
       " <run_classifier.InputExample at 0x135224e54a8>,\n",
       " <run_classifier.InputExample at 0x135224e54e0>,\n",
       " <run_classifier.InputExample at 0x135224e5518>,\n",
       " <run_classifier.InputExample at 0x135224e5550>,\n",
       " <run_classifier.InputExample at 0x135224e5588>,\n",
       " <run_classifier.InputExample at 0x135224e55c0>,\n",
       " <run_classifier.InputExample at 0x135224e55f8>,\n",
       " <run_classifier.InputExample at 0x135224e5630>,\n",
       " <run_classifier.InputExample at 0x135224e5668>,\n",
       " <run_classifier.InputExample at 0x135224e56a0>,\n",
       " <run_classifier.InputExample at 0x135224e56d8>,\n",
       " <run_classifier.InputExample at 0x135224e5710>,\n",
       " <run_classifier.InputExample at 0x135224e5748>,\n",
       " <run_classifier.InputExample at 0x135224e5780>,\n",
       " <run_classifier.InputExample at 0x135224e57b8>,\n",
       " <run_classifier.InputExample at 0x135224e57f0>,\n",
       " <run_classifier.InputExample at 0x135224e5828>,\n",
       " <run_classifier.InputExample at 0x135224e5860>,\n",
       " <run_classifier.InputExample at 0x135224e5898>,\n",
       " <run_classifier.InputExample at 0x135224e58d0>,\n",
       " <run_classifier.InputExample at 0x135224e5908>,\n",
       " <run_classifier.InputExample at 0x135224e5940>,\n",
       " <run_classifier.InputExample at 0x135224e5978>,\n",
       " <run_classifier.InputExample at 0x135224e59b0>,\n",
       " <run_classifier.InputExample at 0x135224e59e8>,\n",
       " <run_classifier.InputExample at 0x135224e5a20>,\n",
       " <run_classifier.InputExample at 0x135224e5a58>,\n",
       " <run_classifier.InputExample at 0x135224e5a90>,\n",
       " <run_classifier.InputExample at 0x135224e5ac8>,\n",
       " <run_classifier.InputExample at 0x135224e5b00>,\n",
       " <run_classifier.InputExample at 0x135224e5b38>,\n",
       " <run_classifier.InputExample at 0x135224e5b70>,\n",
       " <run_classifier.InputExample at 0x135224e5ba8>,\n",
       " <run_classifier.InputExample at 0x135224e5be0>,\n",
       " <run_classifier.InputExample at 0x135224e5c18>,\n",
       " <run_classifier.InputExample at 0x135224e5c50>,\n",
       " <run_classifier.InputExample at 0x135224e5c88>,\n",
       " <run_classifier.InputExample at 0x135224e5cc0>,\n",
       " <run_classifier.InputExample at 0x135224e5cf8>,\n",
       " <run_classifier.InputExample at 0x135224e5d30>,\n",
       " <run_classifier.InputExample at 0x135224e5d68>,\n",
       " <run_classifier.InputExample at 0x135224e5da0>,\n",
       " <run_classifier.InputExample at 0x135224e5dd8>,\n",
       " <run_classifier.InputExample at 0x135224e5e10>,\n",
       " <run_classifier.InputExample at 0x135224e5e48>,\n",
       " <run_classifier.InputExample at 0x135224e5e80>,\n",
       " <run_classifier.InputExample at 0x135224e5eb8>,\n",
       " <run_classifier.InputExample at 0x135224e5ef0>,\n",
       " <run_classifier.InputExample at 0x135224e5f28>,\n",
       " <run_classifier.InputExample at 0x135224e5f60>,\n",
       " <run_classifier.InputExample at 0x135224e5f98>,\n",
       " <run_classifier.InputExample at 0x135224e5fd0>,\n",
       " <run_classifier.InputExample at 0x135224e9048>,\n",
       " <run_classifier.InputExample at 0x135224e9080>,\n",
       " <run_classifier.InputExample at 0x135224e90b8>,\n",
       " <run_classifier.InputExample at 0x135224e90f0>,\n",
       " <run_classifier.InputExample at 0x135224e9128>,\n",
       " <run_classifier.InputExample at 0x135224e9160>,\n",
       " <run_classifier.InputExample at 0x135224e9198>,\n",
       " <run_classifier.InputExample at 0x135224e91d0>,\n",
       " <run_classifier.InputExample at 0x135224e9208>,\n",
       " <run_classifier.InputExample at 0x135224e9240>,\n",
       " <run_classifier.InputExample at 0x135224e9278>,\n",
       " <run_classifier.InputExample at 0x135224e92b0>,\n",
       " <run_classifier.InputExample at 0x135224e92e8>,\n",
       " <run_classifier.InputExample at 0x135224e9320>,\n",
       " <run_classifier.InputExample at 0x135224e9358>,\n",
       " <run_classifier.InputExample at 0x135224e9390>,\n",
       " <run_classifier.InputExample at 0x135224e93c8>,\n",
       " <run_classifier.InputExample at 0x135224e9400>,\n",
       " <run_classifier.InputExample at 0x135224e9438>,\n",
       " <run_classifier.InputExample at 0x135224e9470>,\n",
       " <run_classifier.InputExample at 0x135224e94a8>,\n",
       " <run_classifier.InputExample at 0x135224e94e0>,\n",
       " <run_classifier.InputExample at 0x135224e9518>,\n",
       " <run_classifier.InputExample at 0x135224e9550>,\n",
       " <run_classifier.InputExample at 0x135224e9588>,\n",
       " <run_classifier.InputExample at 0x135224e95c0>,\n",
       " <run_classifier.InputExample at 0x135224e95f8>,\n",
       " <run_classifier.InputExample at 0x135224e9630>,\n",
       " <run_classifier.InputExample at 0x135224e9668>,\n",
       " <run_classifier.InputExample at 0x135224e96a0>,\n",
       " <run_classifier.InputExample at 0x135224e96d8>,\n",
       " <run_classifier.InputExample at 0x135224e9710>,\n",
       " <run_classifier.InputExample at 0x135224e9748>,\n",
       " <run_classifier.InputExample at 0x135224e9780>,\n",
       " <run_classifier.InputExample at 0x135224e97b8>,\n",
       " <run_classifier.InputExample at 0x135224e97f0>,\n",
       " <run_classifier.InputExample at 0x135224e9828>,\n",
       " <run_classifier.InputExample at 0x135224e9860>,\n",
       " <run_classifier.InputExample at 0x135224e9898>,\n",
       " <run_classifier.InputExample at 0x135224e98d0>,\n",
       " <run_classifier.InputExample at 0x135224e9908>,\n",
       " <run_classifier.InputExample at 0x135224e9940>,\n",
       " <run_classifier.InputExample at 0x135224e9978>,\n",
       " <run_classifier.InputExample at 0x135224e99b0>,\n",
       " <run_classifier.InputExample at 0x135224e99e8>,\n",
       " <run_classifier.InputExample at 0x135224e9a20>,\n",
       " <run_classifier.InputExample at 0x135224e9a58>,\n",
       " <run_classifier.InputExample at 0x135224e9a90>,\n",
       " <run_classifier.InputExample at 0x135224e9ac8>,\n",
       " <run_classifier.InputExample at 0x135224e9b00>,\n",
       " <run_classifier.InputExample at 0x135224e9b38>,\n",
       " <run_classifier.InputExample at 0x135224e9b70>,\n",
       " <run_classifier.InputExample at 0x135224e9ba8>,\n",
       " <run_classifier.InputExample at 0x135224e9be0>,\n",
       " <run_classifier.InputExample at 0x135224e9c18>,\n",
       " <run_classifier.InputExample at 0x135224e9c50>,\n",
       " <run_classifier.InputExample at 0x135224e9c88>,\n",
       " <run_classifier.InputExample at 0x135224e9cc0>,\n",
       " <run_classifier.InputExample at 0x135224e9cf8>,\n",
       " <run_classifier.InputExample at 0x135224e9d30>,\n",
       " <run_classifier.InputExample at 0x135224e9d68>,\n",
       " <run_classifier.InputExample at 0x135224e9da0>,\n",
       " <run_classifier.InputExample at 0x135224e9dd8>,\n",
       " <run_classifier.InputExample at 0x135224e9e10>,\n",
       " <run_classifier.InputExample at 0x135224e9e48>,\n",
       " <run_classifier.InputExample at 0x135224e9e80>,\n",
       " <run_classifier.InputExample at 0x135224e9eb8>,\n",
       " <run_classifier.InputExample at 0x135224e9ef0>,\n",
       " <run_classifier.InputExample at 0x135224e9f28>,\n",
       " <run_classifier.InputExample at 0x135224e9f60>,\n",
       " <run_classifier.InputExample at 0x135224e9f98>,\n",
       " <run_classifier.InputExample at 0x135224e9fd0>,\n",
       " <run_classifier.InputExample at 0x135224ec048>,\n",
       " <run_classifier.InputExample at 0x135224ec080>,\n",
       " <run_classifier.InputExample at 0x135224ec0b8>,\n",
       " <run_classifier.InputExample at 0x135224ec0f0>,\n",
       " <run_classifier.InputExample at 0x135224ec128>,\n",
       " <run_classifier.InputExample at 0x135224ec160>,\n",
       " <run_classifier.InputExample at 0x135224ec198>,\n",
       " <run_classifier.InputExample at 0x135224ec1d0>,\n",
       " <run_classifier.InputExample at 0x135224ec208>,\n",
       " <run_classifier.InputExample at 0x135224ec240>,\n",
       " <run_classifier.InputExample at 0x135224ec278>,\n",
       " <run_classifier.InputExample at 0x135224ec2b0>,\n",
       " <run_classifier.InputExample at 0x135224ec2e8>,\n",
       " <run_classifier.InputExample at 0x135224ec320>,\n",
       " <run_classifier.InputExample at 0x135224ec358>,\n",
       " <run_classifier.InputExample at 0x135224ec390>,\n",
       " <run_classifier.InputExample at 0x135224ec3c8>,\n",
       " <run_classifier.InputExample at 0x135224ec400>,\n",
       " <run_classifier.InputExample at 0x135224ec438>,\n",
       " <run_classifier.InputExample at 0x135224ec470>,\n",
       " <run_classifier.InputExample at 0x135224ec4a8>,\n",
       " <run_classifier.InputExample at 0x135224ec4e0>,\n",
       " <run_classifier.InputExample at 0x135224ec518>,\n",
       " <run_classifier.InputExample at 0x135224ec550>,\n",
       " <run_classifier.InputExample at 0x135224ec588>,\n",
       " <run_classifier.InputExample at 0x135224ec5c0>,\n",
       " <run_classifier.InputExample at 0x135224ec5f8>,\n",
       " <run_classifier.InputExample at 0x135224ec630>,\n",
       " <run_classifier.InputExample at 0x135224ec668>,\n",
       " <run_classifier.InputExample at 0x135224ec6a0>,\n",
       " <run_classifier.InputExample at 0x135224ec6d8>,\n",
       " <run_classifier.InputExample at 0x135224ec710>,\n",
       " <run_classifier.InputExample at 0x135224ec748>,\n",
       " <run_classifier.InputExample at 0x135224ec780>,\n",
       " <run_classifier.InputExample at 0x135224ec7b8>,\n",
       " <run_classifier.InputExample at 0x135224ec7f0>,\n",
       " <run_classifier.InputExample at 0x135224ec828>,\n",
       " <run_classifier.InputExample at 0x135224ec860>,\n",
       " <run_classifier.InputExample at 0x135224ec898>,\n",
       " <run_classifier.InputExample at 0x135224ec8d0>,\n",
       " <run_classifier.InputExample at 0x135224ec908>,\n",
       " <run_classifier.InputExample at 0x135224ec940>,\n",
       " <run_classifier.InputExample at 0x135224ec978>,\n",
       " <run_classifier.InputExample at 0x135224ec9b0>,\n",
       " <run_classifier.InputExample at 0x135224ec9e8>,\n",
       " <run_classifier.InputExample at 0x135224eca20>,\n",
       " <run_classifier.InputExample at 0x135224eca58>,\n",
       " <run_classifier.InputExample at 0x135224eca90>,\n",
       " <run_classifier.InputExample at 0x135224ecac8>,\n",
       " <run_classifier.InputExample at 0x135224ecb00>,\n",
       " <run_classifier.InputExample at 0x135224ecb38>,\n",
       " <run_classifier.InputExample at 0x135224ecb70>,\n",
       " <run_classifier.InputExample at 0x135224ecba8>,\n",
       " <run_classifier.InputExample at 0x135224ecbe0>,\n",
       " <run_classifier.InputExample at 0x135224ecc18>,\n",
       " <run_classifier.InputExample at 0x135224ecc50>,\n",
       " <run_classifier.InputExample at 0x135224ecc88>,\n",
       " <run_classifier.InputExample at 0x135224eccc0>,\n",
       " <run_classifier.InputExample at 0x135224eccf8>,\n",
       " <run_classifier.InputExample at 0x135224ecd30>,\n",
       " <run_classifier.InputExample at 0x135224ecd68>,\n",
       " <run_classifier.InputExample at 0x135224ecda0>,\n",
       " <run_classifier.InputExample at 0x135224ecdd8>,\n",
       " <run_classifier.InputExample at 0x135224ece10>,\n",
       " <run_classifier.InputExample at 0x135224ece48>,\n",
       " <run_classifier.InputExample at 0x135224ece80>,\n",
       " <run_classifier.InputExample at 0x135224eceb8>,\n",
       " <run_classifier.InputExample at 0x135224ecef0>,\n",
       " <run_classifier.InputExample at 0x135224ecf28>,\n",
       " <run_classifier.InputExample at 0x135224ecf60>,\n",
       " <run_classifier.InputExample at 0x135224ecf98>,\n",
       " <run_classifier.InputExample at 0x135224ecfd0>,\n",
       " <run_classifier.InputExample at 0x135224f2048>,\n",
       " <run_classifier.InputExample at 0x135224f2080>,\n",
       " <run_classifier.InputExample at 0x135224f20b8>,\n",
       " <run_classifier.InputExample at 0x135224f20f0>,\n",
       " <run_classifier.InputExample at 0x135224f2128>,\n",
       " <run_classifier.InputExample at 0x135224f2160>,\n",
       " <run_classifier.InputExample at 0x135224f2198>,\n",
       " <run_classifier.InputExample at 0x135224f21d0>,\n",
       " <run_classifier.InputExample at 0x135224f2208>,\n",
       " <run_classifier.InputExample at 0x135224f2240>,\n",
       " <run_classifier.InputExample at 0x135224f2278>,\n",
       " <run_classifier.InputExample at 0x135224f22b0>,\n",
       " <run_classifier.InputExample at 0x135224f22e8>,\n",
       " <run_classifier.InputExample at 0x135224f2320>,\n",
       " <run_classifier.InputExample at 0x135224f2358>,\n",
       " <run_classifier.InputExample at 0x135224f2390>,\n",
       " <run_classifier.InputExample at 0x135224f23c8>,\n",
       " <run_classifier.InputExample at 0x135224f2400>,\n",
       " <run_classifier.InputExample at 0x135224f2438>,\n",
       " <run_classifier.InputExample at 0x135224f2470>,\n",
       " <run_classifier.InputExample at 0x135224f24a8>,\n",
       " <run_classifier.InputExample at 0x135224f24e0>,\n",
       " <run_classifier.InputExample at 0x135224f2518>,\n",
       " <run_classifier.InputExample at 0x135224f2550>,\n",
       " <run_classifier.InputExample at 0x135224f2588>,\n",
       " <run_classifier.InputExample at 0x135224f25c0>,\n",
       " <run_classifier.InputExample at 0x135224f25f8>,\n",
       " <run_classifier.InputExample at 0x135224f2630>,\n",
       " <run_classifier.InputExample at 0x135224f2668>,\n",
       " <run_classifier.InputExample at 0x135224f26a0>,\n",
       " <run_classifier.InputExample at 0x135224f26d8>,\n",
       " <run_classifier.InputExample at 0x135224f2710>,\n",
       " <run_classifier.InputExample at 0x135224f2748>,\n",
       " <run_classifier.InputExample at 0x135224f2780>,\n",
       " <run_classifier.InputExample at 0x135224f27b8>,\n",
       " <run_classifier.InputExample at 0x135224f27f0>,\n",
       " <run_classifier.InputExample at 0x135224f2828>,\n",
       " <run_classifier.InputExample at 0x135224f2860>,\n",
       " <run_classifier.InputExample at 0x135224f2898>,\n",
       " <run_classifier.InputExample at 0x135224f28d0>,\n",
       " <run_classifier.InputExample at 0x135224f2908>,\n",
       " <run_classifier.InputExample at 0x135224f2940>,\n",
       " <run_classifier.InputExample at 0x135224f2978>,\n",
       " <run_classifier.InputExample at 0x135224f29b0>,\n",
       " <run_classifier.InputExample at 0x135224f29e8>,\n",
       " <run_classifier.InputExample at 0x135224f2a20>,\n",
       " <run_classifier.InputExample at 0x135224f2a58>,\n",
       " <run_classifier.InputExample at 0x135224f2a90>,\n",
       " <run_classifier.InputExample at 0x135224f2ac8>,\n",
       " <run_classifier.InputExample at 0x135224f2b00>,\n",
       " <run_classifier.InputExample at 0x135224f2b38>,\n",
       " <run_classifier.InputExample at 0x135224f2b70>,\n",
       " <run_classifier.InputExample at 0x135224f2ba8>,\n",
       " <run_classifier.InputExample at 0x135224f2be0>,\n",
       " <run_classifier.InputExample at 0x135224f2c18>,\n",
       " <run_classifier.InputExample at 0x135224f2c50>,\n",
       " <run_classifier.InputExample at 0x135224f2c88>,\n",
       " <run_classifier.InputExample at 0x135224f2cc0>,\n",
       " <run_classifier.InputExample at 0x135224f2cf8>,\n",
       " <run_classifier.InputExample at 0x135224f2d30>,\n",
       " <run_classifier.InputExample at 0x135224f2d68>,\n",
       " <run_classifier.InputExample at 0x135224f2da0>,\n",
       " <run_classifier.InputExample at 0x135224f2dd8>,\n",
       " <run_classifier.InputExample at 0x135224f2e10>,\n",
       " <run_classifier.InputExample at 0x135224f2e48>,\n",
       " <run_classifier.InputExample at 0x135224f2e80>,\n",
       " <run_classifier.InputExample at 0x135224f2eb8>,\n",
       " <run_classifier.InputExample at 0x135224f2ef0>,\n",
       " <run_classifier.InputExample at 0x135224f2f28>,\n",
       " <run_classifier.InputExample at 0x135224f2f60>,\n",
       " <run_classifier.InputExample at 0x135224f2f98>,\n",
       " <run_classifier.InputExample at 0x135224f2fd0>,\n",
       " <run_classifier.InputExample at 0x135224f6048>,\n",
       " <run_classifier.InputExample at 0x135224f6080>,\n",
       " <run_classifier.InputExample at 0x135224f60b8>,\n",
       " <run_classifier.InputExample at 0x135224f60f0>,\n",
       " <run_classifier.InputExample at 0x135224f6128>,\n",
       " <run_classifier.InputExample at 0x135224f6160>,\n",
       " <run_classifier.InputExample at 0x135224f6198>,\n",
       " <run_classifier.InputExample at 0x135224f61d0>,\n",
       " <run_classifier.InputExample at 0x135224f6208>,\n",
       " <run_classifier.InputExample at 0x135224f6240>,\n",
       " <run_classifier.InputExample at 0x135224f6278>,\n",
       " <run_classifier.InputExample at 0x135224f62b0>,\n",
       " <run_classifier.InputExample at 0x135224f62e8>,\n",
       " <run_classifier.InputExample at 0x135224f6320>,\n",
       " <run_classifier.InputExample at 0x135224f6358>,\n",
       " <run_classifier.InputExample at 0x135224f6390>,\n",
       " <run_classifier.InputExample at 0x135224f63c8>,\n",
       " <run_classifier.InputExample at 0x135224f6400>,\n",
       " <run_classifier.InputExample at 0x135224f6438>,\n",
       " <run_classifier.InputExample at 0x135224f6470>,\n",
       " <run_classifier.InputExample at 0x135224f64a8>,\n",
       " <run_classifier.InputExample at 0x135224f64e0>,\n",
       " <run_classifier.InputExample at 0x135224f6518>,\n",
       " <run_classifier.InputExample at 0x135224f6550>,\n",
       " <run_classifier.InputExample at 0x135224f6588>,\n",
       " <run_classifier.InputExample at 0x135224f65c0>,\n",
       " <run_classifier.InputExample at 0x135224f65f8>,\n",
       " <run_classifier.InputExample at 0x135224f6630>,\n",
       " <run_classifier.InputExample at 0x135224f6668>,\n",
       " <run_classifier.InputExample at 0x135224f66a0>,\n",
       " <run_classifier.InputExample at 0x135224f66d8>,\n",
       " <run_classifier.InputExample at 0x135224f6710>,\n",
       " <run_classifier.InputExample at 0x135224f6748>,\n",
       " <run_classifier.InputExample at 0x135224f6780>,\n",
       " <run_classifier.InputExample at 0x135224f67b8>,\n",
       " <run_classifier.InputExample at 0x135224f67f0>,\n",
       " <run_classifier.InputExample at 0x135224f6828>,\n",
       " <run_classifier.InputExample at 0x135224f6860>,\n",
       " <run_classifier.InputExample at 0x135224f6898>,\n",
       " <run_classifier.InputExample at 0x135224f68d0>,\n",
       " <run_classifier.InputExample at 0x135224f6908>,\n",
       " <run_classifier.InputExample at 0x135224f6940>,\n",
       " <run_classifier.InputExample at 0x135224f6978>,\n",
       " <run_classifier.InputExample at 0x135224f69b0>,\n",
       " <run_classifier.InputExample at 0x135224f69e8>,\n",
       " <run_classifier.InputExample at 0x135224f6a20>,\n",
       " <run_classifier.InputExample at 0x135224f6a58>,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune and Run Predictions on a pretrained BERT Model from TF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force TF Hub writes to the GS bucket we provide\n",
    "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'././bucket//bert-tfhub/models/MRPC'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_training, input_ids, input_mask, \n",
    "                 segment_ids, labels,\n",
    "                 num_labels, bert_hub_module_handle):\n",
    "    \"\"\"Creates a classification model.\"\"\"\n",
    "    tags = set()\n",
    "    if is_training:\n",
    "        tags.add(\"train\")\n",
    "    bert_module = hub.Module(bert_hub_module_handle, \n",
    "                             tags=tags, trainable=True)\n",
    "    bert_inputs = dict(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "        inputs=bert_inputs,\n",
    "        signature=\"tokens\",\n",
    "        as_dict=True)\n",
    "\n",
    "    # In the demo, we are doing a simple classification task on the entire\n",
    "    # segment.\n",
    "    #\n",
    "    # If you want to use the token-level output, use\n",
    "    # bert_outputs[\"sequence_output\"] instead.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        if is_training:\n",
    "          # I.e., 0.1 dropout\n",
    "          output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "\n",
    "    return (loss, per_example_loss, logits, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps, use_tpu, bert_hub_module_handle):\n",
    "    def model_fn(features, labels, mode, params):  \n",
    "        tf.logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            tf.logging.info(\"  name = %s, shape = %s\" % (\n",
    "                name, features[name].shape))\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "        (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
    "            is_training, input_ids, input_mask, segment_ids, label_ids, num_labels,\n",
    "            bert_hub_module_handle)\n",
    "        \n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = optimization.create_optimizer(\n",
    "                  total_loss, learning_rate, num_train_steps, \n",
    "                  num_warmup_steps, use_tpu)\n",
    "\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                train_op=train_op)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            eval_metrics = {\n",
    "                'eval_accuracy' : tf.metrics.accuracy(label_ids, \n",
    "                                tf.argmax(logits, axis=-1, \n",
    "                                          output_type=tf.int32)),\n",
    "                'eval_loss' : tf.metrics.mean(per_example_loss)\n",
    "            }\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                eval_metric_ops=eval_metrics)\n",
    "        elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode, \n",
    "                predictions={\"probabilities\": probabilities})\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Only TRAIN, EVAL and PREDICT modes are supported: %s\" % \n",
    "                (mode))\n",
    "        return output_spec\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "    num_labels=len(label_list),\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False,\n",
    "    bert_hub_module_handle=BERT_MODEL_HUB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_config(output_dir):\n",
    "    return tf.estimator.RunConfig(\n",
    "        model_dir=output_dir,\n",
    "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '././bucket//bert-tfhub/models/MRPC', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000204B3A67EB8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '././bucket//bert-tfhub/models/MRPC', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000204B3A67EB8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    config=get_run_config(OUTPUT_DIR),\n",
    "    params={\n",
    "        'batch_size' : TRAIN_BATCH_SIZE,\n",
    "#         'eval_batch_size' : EVAL_BATCH_SIZE,\n",
    "#         'predict_batch_size' : PREDICT_BATCH_SIZE\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def model_train(estimator):\n",
    "    print('MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...')\n",
    "    # We'll set sequences to be at most 128 tokens long.\n",
    "    train_features = run_classifier.convert_examples_to_features(\n",
    "        train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
    "    print('  Num examples = {}'.format(len(train_examples)))\n",
    "    print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
    "    tf.logging.info('  Num steps = %d', num_train_steps)\n",
    "    train_input_fn = run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=True)\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "    print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...\n",
      "INFO:tensorflow:Writing example 0 of 3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 3668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] am ##ro ##zi accused his brother , whom he called \" the witness \" , of deliberately di ##stor ##ting his evidence . [SEP] referring to him as only \" the witness \" , am ##ro ##zi accused his brother of deliberately di ##stor ##ting his evidence . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] am ##ro ##zi accused his brother , whom he called \" the witness \" , of deliberately di ##stor ##ting his evidence . [SEP] referring to him as only \" the witness \" , am ##ro ##zi accused his brother of deliberately di ##stor ##ting his evidence . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2572 3217 5831 5496 2010 2567 1010 3183 2002 2170 1000 1996 7409 1000 1010 1997 9969 4487 23809 3436 2010 3350 1012 102 7727 2000 2032 2004 2069 1000 1996 7409 1000 1010 2572 3217 5831 5496 2010 2567 1997 9969 4487 23809 3436 2010 3350 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2572 3217 5831 5496 2010 2567 1010 3183 2002 2170 1000 1996 7409 1000 1010 1997 9969 4487 23809 3436 2010 3350 1012 102 7727 2000 2032 2004 2069 1000 1996 7409 1000 1010 2572 3217 5831 5496 2010 2567 1997 9969 4487 23809 3436 2010 3350 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] yu ##ca ##ip ##a owned dominic ##k ' s before selling the chain to safe ##way in 1998 for $ 2 . 5 billion . [SEP] yu ##ca ##ip ##a bought dominic ##k ' s in 1995 for $ 69 ##3 million and sold it to safe ##way for $ 1 . 8 billion in 1998 . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] yu ##ca ##ip ##a owned dominic ##k ' s before selling the chain to safe ##way in 1998 for $ 2 . 5 billion . [SEP] yu ##ca ##ip ##a bought dominic ##k ' s in 1995 for $ 69 ##3 million and sold it to safe ##way for $ 1 . 8 billion in 1998 . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 9805 3540 11514 2050 3079 11282 2243 1005 1055 2077 4855 1996 4677 2000 3647 4576 1999 2687 2005 1002 1016 1012 1019 4551 1012 102 9805 3540 11514 2050 4149 11282 2243 1005 1055 1999 2786 2005 1002 6353 2509 2454 1998 2853 2009 2000 3647 4576 2005 1002 1015 1012 1022 4551 1999 2687 1012 102 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 9805 3540 11514 2050 3079 11282 2243 1005 1055 2077 4855 1996 4677 2000 3647 4576 1999 2687 2005 1002 1016 1012 1019 4551 1012 102 9805 3540 11514 2050 4149 11282 2243 1005 1055 1999 2786 2005 1002 6353 2509 2454 1998 2853 2009 2000 3647 4576 2005 1002 1015 1012 1022 4551 1999 2687 1012 102 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] they had published an advertisement on the internet on june 10 , offering the cargo for sale , he added . [SEP] on june 10 , the ship ' s owners had published an advertisement on the internet , offering the explosives for sale . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] they had published an advertisement on the internet on june 10 , offering the cargo for sale , he added . [SEP] on june 10 , the ship ' s owners had published an advertisement on the internet , offering the explosives for sale . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2027 2018 2405 2019 15147 2006 1996 4274 2006 2238 2184 1010 5378 1996 6636 2005 5096 1010 2002 2794 1012 102 2006 2238 2184 1010 1996 2911 1005 1055 5608 2018 2405 2019 15147 2006 1996 4274 1010 5378 1996 14792 2005 5096 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2027 2018 2405 2019 15147 2006 1996 4274 2006 2238 2184 1010 5378 1996 6636 2005 5096 1010 2002 2794 1012 102 2006 2238 2184 1010 1996 2911 1005 1055 5608 2018 2405 2019 15147 2006 1996 4274 1010 5378 1996 14792 2005 5096 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] around 03 ##35 gm ##t , tab shares were up 19 cents , or 4 . 4 % , at a $ 4 . 56 , having earlier set a record high of a $ 4 [SEP] tab shares jumped 20 cents , or 4 . 6 % , to set a record closing high at a $ 4 . 57 . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] around 03 ##35 gm ##t , tab shares were up 19 cents , or 4 . 4 % , at a $ 4 . 56 , having earlier set a record high of a $ 4 [SEP] tab shares jumped 20 cents , or 4 . 6 % , to set a record closing high at a $ 4 . 57 . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2105 6021 19481 13938 2102 1010 21628 6661 2020 2039 2539 16653 1010 2030 1018 1012 1018 1003 1010 2012 1037 1002 1018 1012 5179 1010 2383 3041 2275 1037 2501 2152 1997 1037 1002 1018 102 21628 6661 5598 2322 16653 1010 2030 1018 1012 1020 1003 1010 2000 2275 1037 2501 5494 2152 2012 1037 1002 1018 1012 5401 1012 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2105 6021 19481 13938 2102 1010 21628 6661 2020 2039 2539 16653 1010 2030 1018 1012 1018 1003 1010 2012 1037 1002 1018 1012 5179 1010 2383 3041 2275 1037 2501 2152 1997 1037 1002 1018 102 21628 6661 5598 2322 16653 1010 2030 1018 1012 1020 1003 1010 2000 2275 1037 2501 5494 2152 2012 1037 1002 1018 1012 5401 1012 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: train-5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the stock rose $ 2 . 11 , or about 11 percent , to close friday at $ 21 . 51 on the new york stock exchange . [SEP] pg & e corp . shares jumped $ 1 . 63 or 8 percent to $ 21 . 03 on the new york stock exchange on friday . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the stock rose $ 2 . 11 , or about 11 percent , to close friday at $ 21 . 51 on the new york stock exchange . [SEP] pg & e corp . shares jumped $ 1 . 63 or 8 percent to $ 21 . 03 on the new york stock exchange on friday . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 4518 3123 1002 1016 1012 2340 1010 2030 2055 2340 3867 1010 2000 2485 5958 2012 1002 2538 1012 4868 2006 1996 2047 2259 4518 3863 1012 102 18720 1004 1041 13058 1012 6661 5598 1002 1015 1012 6191 2030 1022 3867 2000 1002 2538 1012 6021 2006 1996 2047 2259 4518 3863 2006 5958 1012 102 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 4518 3123 1002 1016 1012 2340 1010 2030 2055 2340 3867 1010 2000 2485 5958 2012 1002 2538 1012 4868 2006 1996 2047 2259 4518 3863 1012 102 18720 1004 1041 13058 1012 6661 5598 1002 1015 1012 6191 2030 1022 3867 2000 1002 2538 1012 6021 2006 1996 2047 2259 4518 3863 2006 5958 1012 102 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Started training at 2019-12-13 19:30:06.926777 *****\n",
      "  Num examples = 3668\n",
      "  Batch size = 16\n",
      "INFO:tensorflow:  Num steps = 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Num steps = 687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Finished training at 2019-12-13 19:30:06.937780 *****\n"
     ]
    }
   ],
   "source": [
    "model_train(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(estimator):\n",
    "    # Eval the model\n",
    "    eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
    "    eval_features = run_classifier.convert_examples_to_features(\n",
    "        eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
    "    print('  Num examples = {}'.format(len(eval_examples)))\n",
    "    print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
    "    eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
    "    eval_input_fn = run_classifier.input_fn_builder(\n",
    "        features=eval_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=True)\n",
    "    result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
    "    print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
    "    output_eval_file = os.path.join(OUTPUT_DIR, 'eval_results.txt')\n",
    "    with tf.gfile.GFile(output_eval_file, 'w') as writer:\n",
    "        print('***** Eval results *****')\n",
    "        for key in sorted(result.keys()):\n",
    "            print('  {} = {}'.format(key, str(result[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] he said the foods ##er ##vic ##e pie business doesn ' t fit the company ' s long - term growth strategy . [SEP] \" the foods ##er ##vic ##e pie business does not fit our long - term growth strategy . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] he said the foods ##er ##vic ##e pie business doesn ' t fit the company ' s long - term growth strategy . [SEP] \" the foods ##er ##vic ##e pie business does not fit our long - term growth strategy . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2002 2056 1996 9440 2121 7903 2063 11345 2449 2987 1005 1056 4906 1996 2194 1005 1055 2146 1011 2744 3930 5656 1012 102 1000 1996 9440 2121 7903 2063 11345 2449 2515 2025 4906 2256 2146 1011 2744 3930 5656 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2002 2056 1996 9440 2121 7903 2063 11345 2449 2987 1005 1056 4906 1996 2194 1005 1055 2146 1011 2744 3930 5656 1012 102 1000 1996 9440 2121 7903 2063 11345 2449 2515 2025 4906 2256 2146 1011 2744 3930 5656 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] magna ##relli said ra ##cic ##ot hated the iraqi regime and looked forward to using his long years of training in the war . [SEP] his wife said he was \" 100 percent behind george bush \" and looked forward to using his years of training in the war . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] magna ##relli said ra ##cic ##ot hated the iraqi regime and looked forward to using his long years of training in the war . [SEP] his wife said he was \" 100 percent behind george bush \" and looked forward to using his years of training in the war . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 20201 22948 2056 10958 19053 4140 6283 1996 8956 6939 1998 2246 2830 2000 2478 2010 2146 2086 1997 2731 1999 1996 2162 1012 102 2010 2564 2056 2002 2001 1000 2531 3867 2369 2577 5747 1000 1998 2246 2830 2000 2478 2010 2086 1997 2731 1999 1996 2162 1012 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 20201 22948 2056 10958 19053 4140 6283 1996 8956 6939 1998 2246 2830 2000 2478 2010 2146 2086 1997 2731 1999 1996 2162 1012 102 2010 2564 2056 2002 2001 1000 2531 3867 2369 2577 5747 1000 1998 2246 2830 2000 2478 2010 2086 1997 2731 1999 1996 2162 1012 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the dollar was at 116 . 92 yen against the yen , flat on the session , and at 1 . 289 ##1 against the swiss fran ##c , also flat [SEP] the dollar was at 116 . 78 yen jp ##y = , virtually flat on the session , and at 1 . 287 ##1 against the swiss fran ##c ch [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the dollar was at 116 . 92 yen against the yen , flat on the session , and at 1 . 289 ##1 against the swiss fran ##c , also flat [SEP] the dollar was at 116 . 78 yen jp ##y = , virtually flat on the session , and at 1 . 287 ##1 against the swiss fran ##c ch [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 7922 2001 2012 12904 1012 6227 18371 2114 1996 18371 1010 4257 2006 1996 5219 1010 1998 2012 1015 1012 27054 2487 2114 1996 5364 23151 2278 1010 2036 4257 102 1996 7922 2001 2012 12904 1012 6275 18371 16545 2100 1027 1010 8990 4257 2006 1996 5219 1010 1998 2012 1015 1012 23090 2487 2114 1996 5364 23151 2278 10381 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 7922 2001 2012 12904 1012 6227 18371 2114 1996 18371 1010 4257 2006 1996 5219 1010 1998 2012 1015 1012 27054 2487 2114 1996 5364 23151 2278 1010 2036 4257 102 1996 7922 2001 2012 12904 1012 6275 18371 16545 2100 1027 1010 8990 4257 2006 1996 5219 1010 1998 2012 1015 1012 23090 2487 2114 1996 5364 23151 2278 10381 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the afl - ci ##o is waiting until october to decide if it will end ##ors ##e a candidate . [SEP] the afl - ci ##o announced wednesday that it will decide in october whether to end ##ors ##e a candidate before the primaries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the afl - ci ##o is waiting until october to decide if it will end ##ors ##e a candidate . [SEP] the afl - ci ##o announced wednesday that it will decide in october whether to end ##ors ##e a candidate before the primaries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 10028 1011 25022 2080 2003 3403 2127 2255 2000 5630 2065 2009 2097 2203 5668 2063 1037 4018 1012 102 1996 10028 1011 25022 2080 2623 9317 2008 2009 2097 5630 1999 2255 3251 2000 2203 5668 2063 1037 4018 2077 1996 27419 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 10028 1011 25022 2080 2003 3403 2127 2255 2000 5630 2065 2009 2097 2203 5668 2063 1037 4018 1012 102 1996 10028 1011 25022 2080 2623 9317 2008 2009 2097 5630 1999 2255 3251 2000 2203 5668 2063 1037 4018 2077 1996 27419 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] no dates have been set for the civil or the criminal trial . [SEP] no dates have been set for the criminal or civil cases , but shan ##ley has pleaded not guilty . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] no dates have been set for the civil or the criminal trial . [SEP] no dates have been set for the criminal or civil cases , but shan ##ley has pleaded not guilty . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2053 5246 2031 2042 2275 2005 1996 2942 2030 1996 4735 3979 1012 102 2053 5246 2031 2042 2275 2005 1996 4735 2030 2942 3572 1010 2021 17137 3051 2038 12254 2025 5905 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2053 5246 2031 2042 2275 2005 1996 2942 2030 1996 4735 3979 1012 102 2053 5246 2031 2042 2275 2005 1996 4735 2030 2942 3572 1010 2021 17137 3051 2038 12254 2025 5905 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Started evaluation at 2019-12-13 19:30:07.230293 *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Features ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Features ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_ids, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_ids, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_mask, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_mask, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = label_ids, shape = (16,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = label_ids, shape = (16,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = segment_ids, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = segment_ids, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "명훈이 짱!!\n",
      "\n",
      "\n",
      " Tensor(\"Softmax:0\", shape=(16, 2), dtype=float32)\n",
      "\n",
      "\n",
      "\n",
      "명훈이 짱!!\n",
      "\n",
      "\n",
      " Tensor(\"Softmax:0\", shape=(16, 2), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-12-13T19:30:08Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-12-13T19:30:08Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ././bucket//bert-tfhub/models/MRPC\\model.ckpt-687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ././bucket//bert-tfhub/models/MRPC\\model.ckpt-687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [15/51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [15/51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [25/51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-13-19:30:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-12-13-19:30:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 687: eval_accuracy = 0.8425, eval_loss = 0.5332047, global_step = 687, loss = 0.5332047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 687: eval_accuracy = 0.8425, eval_loss = 0.5332047, global_step = 687, loss = 0.5332047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 687: ././bucket//bert-tfhub/models/MRPC\\model.ckpt-687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 687: ././bucket//bert-tfhub/models/MRPC\\model.ckpt-687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Finished evaluation at 2019-12-13 19:30:11.694768 *****\n",
      "***** Eval results *****\n",
      "  eval_accuracy = 0.8425\n",
      "  eval_loss = 0.5332047\n",
      "  global_step = 687\n",
      "  loss = 0.5332047\n"
     ]
    }
   ],
   "source": [
    "model_eval(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<run_classifier.InputExample at 0x204a7f61390>,\n",
       " <run_classifier.InputExample at 0x204a1751630>,\n",
       " <run_classifier.InputExample at 0x204a1751438>,\n",
       " <run_classifier.InputExample at 0x204a17514a8>,\n",
       " <run_classifier.InputExample at 0x204a1751400>,\n",
       " <run_classifier.InputExample at 0x204a17513c8>,\n",
       " <run_classifier.InputExample at 0x204a1751278>,\n",
       " <run_classifier.InputExample at 0x204a17512b0>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.get_dev_examples(\n",
    "            TASK_DATA_DIR)[:PREDICT_BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(estimator):\n",
    "    # Make predictions on a subset of eval examples\n",
    "    prediction_examples = processor.get_dev_examples(\n",
    "            TASK_DATA_DIR)[:PREDICT_BATCH_SIZE]\n",
    "    input_features = run_classifier.convert_examples_to_features(\n",
    "            prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    predict_input_fn = run_classifier.input_fn_builder(features=input_features,\n",
    "                                                       seq_length=MAX_SEQ_LENGTH,\n",
    "                                                       is_training=False, \n",
    "                                                       drop_remainder=True)\n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    return prediction_examples, predictions\n",
    "#     for example, prediction in zip(prediction_examples, predictions):\n",
    "#         print('text_a: {}\\ntext_b: {}\\nlabel:{}\\nprediction:{}\\n'.format(\n",
    "#                 example.text_a, example.text_b, \n",
    "#                 str(example.label), prediction['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] he said the foods ##er ##vic ##e pie business doesn ' t fit the company ' s long - term growth strategy . [SEP] \" the foods ##er ##vic ##e pie business does not fit our long - term growth strategy . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] he said the foods ##er ##vic ##e pie business doesn ' t fit the company ' s long - term growth strategy . [SEP] \" the foods ##er ##vic ##e pie business does not fit our long - term growth strategy . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2002 2056 1996 9440 2121 7903 2063 11345 2449 2987 1005 1056 4906 1996 2194 1005 1055 2146 1011 2744 3930 5656 1012 102 1000 1996 9440 2121 7903 2063 11345 2449 2515 2025 4906 2256 2146 1011 2744 3930 5656 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2002 2056 1996 9440 2121 7903 2063 11345 2449 2987 1005 1056 4906 1996 2194 1005 1055 2146 1011 2744 3930 5656 1012 102 1000 1996 9440 2121 7903 2063 11345 2449 2515 2025 4906 2256 2146 1011 2744 3930 5656 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] magna ##relli said ra ##cic ##ot hated the iraqi regime and looked forward to using his long years of training in the war . [SEP] his wife said he was \" 100 percent behind george bush \" and looked forward to using his years of training in the war . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] magna ##relli said ra ##cic ##ot hated the iraqi regime and looked forward to using his long years of training in the war . [SEP] his wife said he was \" 100 percent behind george bush \" and looked forward to using his years of training in the war . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 20201 22948 2056 10958 19053 4140 6283 1996 8956 6939 1998 2246 2830 2000 2478 2010 2146 2086 1997 2731 1999 1996 2162 1012 102 2010 2564 2056 2002 2001 1000 2531 3867 2369 2577 5747 1000 1998 2246 2830 2000 2478 2010 2086 1997 2731 1999 1996 2162 1012 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 20201 22948 2056 10958 19053 4140 6283 1996 8956 6939 1998 2246 2830 2000 2478 2010 2146 2086 1997 2731 1999 1996 2162 1012 102 2010 2564 2056 2002 2001 1000 2531 3867 2369 2577 5747 1000 1998 2246 2830 2000 2478 2010 2086 1997 2731 1999 1996 2162 1012 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the dollar was at 116 . 92 yen against the yen , flat on the session , and at 1 . 289 ##1 against the swiss fran ##c , also flat [SEP] the dollar was at 116 . 78 yen jp ##y = , virtually flat on the session , and at 1 . 287 ##1 against the swiss fran ##c ch [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the dollar was at 116 . 92 yen against the yen , flat on the session , and at 1 . 289 ##1 against the swiss fran ##c , also flat [SEP] the dollar was at 116 . 78 yen jp ##y = , virtually flat on the session , and at 1 . 287 ##1 against the swiss fran ##c ch [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 7922 2001 2012 12904 1012 6227 18371 2114 1996 18371 1010 4257 2006 1996 5219 1010 1998 2012 1015 1012 27054 2487 2114 1996 5364 23151 2278 1010 2036 4257 102 1996 7922 2001 2012 12904 1012 6275 18371 16545 2100 1027 1010 8990 4257 2006 1996 5219 1010 1998 2012 1015 1012 23090 2487 2114 1996 5364 23151 2278 10381 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 7922 2001 2012 12904 1012 6227 18371 2114 1996 18371 1010 4257 2006 1996 5219 1010 1998 2012 1015 1012 27054 2487 2114 1996 5364 23151 2278 1010 2036 4257 102 1996 7922 2001 2012 12904 1012 6275 18371 16545 2100 1027 1010 8990 4257 2006 1996 5219 1010 1998 2012 1015 1012 23090 2487 2114 1996 5364 23151 2278 10381 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the afl - ci ##o is waiting until october to decide if it will end ##ors ##e a candidate . [SEP] the afl - ci ##o announced wednesday that it will decide in october whether to end ##ors ##e a candidate before the primaries . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] the afl - ci ##o is waiting until october to decide if it will end ##ors ##e a candidate . [SEP] the afl - ci ##o announced wednesday that it will decide in october whether to end ##ors ##e a candidate before the primaries . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 10028 1011 25022 2080 2003 3403 2127 2255 2000 5630 2065 2009 2097 2203 5668 2063 1037 4018 1012 102 1996 10028 1011 25022 2080 2623 9317 2008 2009 2097 5630 1999 2255 3251 2000 2203 5668 2063 1037 4018 2077 1996 27419 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1996 10028 1011 25022 2080 2003 3403 2127 2255 2000 5630 2065 2009 2097 2203 5668 2063 1037 4018 1012 102 1996 10028 1011 25022 2080 2623 9317 2008 2009 2097 5630 1999 2255 3251 2000 2203 5668 2063 1037 4018 2077 1996 27419 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: dev-5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] no dates have been set for the civil or the criminal trial . [SEP] no dates have been set for the criminal or civil cases , but shan ##ley has pleaded not guilty . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] no dates have been set for the civil or the criminal trial . [SEP] no dates have been set for the criminal or civil cases , but shan ##ley has pleaded not guilty . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2053 5246 2031 2042 2275 2005 1996 2942 2030 1996 4735 3979 1012 102 2053 5246 2031 2042 2275 2005 1996 4735 2030 2942 3572 1010 2021 17137 3051 2038 12254 2025 5905 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2053 5246 2031 2042 2275 2005 1996 2942 2030 1996 4735 3979 1012 102 2053 5246 2031 2042 2275 2005 1996 4735 2030 2942 3572 1010 2021 17137 3051 2038 12254 2025 5905 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "prediction_examples, predictions = model_predict(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Features ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Features ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_ids, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_ids, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_mask, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = input_mask, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = label_ids, shape = (16,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = label_ids, shape = (16,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = segment_ids, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = segment_ids, shape = (16, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "명훈이 짱!!\n",
      "\n",
      "\n",
      " Tensor(\"Softmax:0\", shape=(16, 2), dtype=float32)\n",
      "\n",
      "\n",
      "\n",
      "명훈이 짱!!\n",
      "\n",
      "\n",
      " Tensor(\"Softmax:0\", shape=(16, 2), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ././bucket//bert-tfhub/models/MRPC\\model.ckpt-687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ././bucket//bert-tfhub/models/MRPC\\model.ckpt-687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "for example, prediction in zip(prediction_examples, predictions):\n",
    "    print('text_a: {}\\ntext_b: {}\\nlabel:{}\\nprediction:{}\\n'.format(\n",
    "            example.text_a, example.text_b, \n",
    "            str(example.label), prediction['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He said the foodservice pie business doesn 't fit the company 's long-term growth strategy .\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_examples[0].text_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" The foodservice pie business does not fit our long-term growth strategy .'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_examples[0].text_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(prediction_examples[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[prediction for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
